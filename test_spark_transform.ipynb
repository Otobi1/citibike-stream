{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-02T14:52:39.155128Z",
     "start_time": "2025-01-02T14:52:39.040056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from functools import cache\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T14:52:41.218746Z",
     "start_time": "2025-01-02T14:52:41.216938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# pyspark.__version__\n",
    "# pyspark.__file__\n",
    "# pwd"
   ],
   "id": "b93434313faeb955",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T14:52:45.412257Z",
     "start_time": "2025-01-02T14:52:42.791801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "jdbc_driver_path = \"./python_app/jars/postgresql-42.5.4.jar\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"testCitiBikeStationStatusTransform\") \\\n",
    "    .config(\"spark.jars\", jdbc_driver_path) \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.memory.fraction\", \"0.8\") \\\n",
    "    .master(\"local[4]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"INFO\")"
   ],
   "id": "4cf99d8809e9f8ba",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 15:52:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T14:52:54.129769Z",
     "start_time": "2025-01-02T14:52:54.126436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# POSTGRESQL connection parameters\n",
    "# POSTGRESQL_HOST = \"postgres\"\n",
    "POSTGRESQL_PORT = \"5432\"\n",
    "POSTGRES_DB = \"citibike_db\"\n",
    "POSTGRES_USER = \"citibike_user\"\n",
    "POSTGRES_PASSWORD = \"citibike_pass\"\n",
    "\n",
    "# JDBC URL\n",
    "# jdbc_url = f\"jdbc:postgresql://{POSTGRESQL_HOST}:{POSTGRESQL_PORT}/{POSTGRES_DB}\"\n",
    "\n",
    "jdbc_url = f\"jdbc:postgresql://localhost:{POSTGRESQL_PORT}/{POSTGRES_DB}\"\n",
    "\n",
    "# Connection properties\n",
    "connection_properties = {\n",
    "    \"user\": POSTGRES_USER,\n",
    "    \"password\": POSTGRES_PASSWORD,\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}"
   ],
   "id": "54fc4d79fe6a3ffc",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T14:53:00.111103Z",
     "start_time": "2025-01-02T14:52:58.942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_station_status = spark.read \\\n",
    "    .jdbc(url=jdbc_url,\n",
    "          table=\"station_status\",\n",
    "          properties=connection_properties\n",
    "          )\n",
    "df_station_status.printSchema()"
   ],
   "id": "81fea84b3fc4eb2a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 15:52:58 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
      "25/01/02 15:52:58 INFO SharedState: Warehouse path is 'file:/Users/tobi/Documents/projects/citibike-stream/spark-warehouse'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- station_id: string (nullable = true)\n",
      " |-- num_bikes_available: integer (nullable = true)\n",
      " |-- num_docks_available: integer (nullable = true)\n",
      " |-- is_installed: boolean (nullable = true)\n",
      " |-- is_renting: boolean (nullable = true)\n",
      " |-- is_returning: boolean (nullable = true)\n",
      " |-- last_reported: timestamp (nullable = true)\n",
      " |-- inserted_at: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T14:53:39.880847Z",
     "start_time": "2025-01-02T14:53:39.800249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_station_info = spark.read \\\n",
    "    .jdbc(url=jdbc_url,\n",
    "            table=\"station_information\",\n",
    "            properties=connection_properties\n",
    "            )\n",
    "df_station_info.printSchema()"
   ],
   "id": "2c6d1bdcc8a40c70",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- station_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- short_name: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- lon: double (nullable = true)\n",
      " |-- region_id: string (nullable = true)\n",
      " |-- capacity: integer (nullable = true)\n",
      " |-- eightd_has_key_dispenser: boolean (nullable = true)\n",
      " |-- has_kiosk: boolean (nullable = true)\n",
      " |-- installed: boolean (nullable = true)\n",
      " |-- last_reported: timestamp (nullable = true)\n",
      " |-- created_at: timestamp (nullable = true)\n",
      " |-- updated_at: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T14:54:38.841287Z",
     "start_time": "2025-01-02T14:54:38.773977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_tripdata = spark.read \\\n",
    "    .jdbc(url=jdbc_url,\n",
    "            table=\"tripdata\",\n",
    "            properties=connection_properties\n",
    "            )\n",
    "df_tripdata.printSchema()"
   ],
   "id": "ada915955f7d74c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ride_id: string (nullable = true)\n",
      " |-- rideable_type: string (nullable = true)\n",
      " |-- started_at: timestamp (nullable = true)\n",
      " |-- ended_at: timestamp (nullable = true)\n",
      " |-- start_station_name: string (nullable = true)\n",
      " |-- start_station_id: string (nullable = true)\n",
      " |-- end_station_name: string (nullable = true)\n",
      " |-- end_station_id: string (nullable = true)\n",
      " |-- start_lat: decimal(9,6) (nullable = true)\n",
      " |-- start_lng: decimal(9,6) (nullable = true)\n",
      " |-- end_lat: decimal(9,6) (nullable = true)\n",
      " |-- end_lng: decimal(9,6) (nullable = true)\n",
      " |-- member_casual: string (nullable = true)\n",
      " |-- month: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T14:57:42.804119Z",
     "start_time": "2025-01-02T14:57:39.062638Z"
    }
   },
   "cell_type": "code",
   "source": "df_station_status.show(5)",
   "id": "d09b6dd2489ab9f4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 15:57:39 INFO CodeGenerator: Code generated in 175.627416 ms\n",
      "25/01/02 15:57:39 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "25/01/02 15:57:39 INFO DAGScheduler: Got job 0 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/01/02 15:57:39 INFO DAGScheduler: Final stage: ResultStage 0 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/01/02 15:57:39 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/01/02 15:57:39 INFO DAGScheduler: Missing parents: List()\n",
      "25/01/02 15:57:39 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/01/02 15:57:39 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 15.7 KiB, free 6.2 GiB)\n",
      "25/01/02 15:57:40 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 6.2 GiB)\n",
      "25/01/02 15:57:40 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on macbookpro.fritz.box:53671 (size: 7.3 KiB, free: 6.2 GiB)\n",
      "25/01/02 15:57:40 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585\n",
      "25/01/02 15:57:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/01/02 15:57:40 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0\n",
      "25/01/02 15:57:40 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (macbookpro.fritz.box, executor driver, partition 0, PROCESS_LOCAL, 9033 bytes) \n",
      "25/01/02 15:57:40 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)\n",
      "25/01/02 15:57:42 INFO CodeGenerator: Code generated in 15.965959 ms(0 + 1) / 1]\n",
      "25/01/02 15:57:42 INFO JDBCRDD: closed connection\n",
      "25/01/02 15:57:42 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2127 bytes result sent to driver\n",
      "25/01/02 15:57:42 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1923 ms on macbookpro.fritz.box (executor driver) (1/1)\n",
      "25/01/02 15:57:42 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "25/01/02 15:57:42 INFO DAGScheduler: ResultStage 0 (showString at NativeMethodAccessorImpl.java:0) finished in 2,401 s\n",
      "25/01/02 15:57:42 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/01/02 15:57:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished\n",
      "25/01/02 15:57:42 INFO DAGScheduler: Job 0 finished: showString at NativeMethodAccessorImpl.java:0, took 2,427383 s\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-------------------+-------------------+------------+----------+------------+-------------------+--------------------+\n",
      "| id|          station_id|num_bikes_available|num_docks_available|is_installed|is_renting|is_returning|      last_reported|         inserted_at|\n",
      "+---+--------------------+-------------------+-------------------+------------+----------+------------+-------------------+--------------------+\n",
      "|  1|816e50eb-dc4b-47d...|                  0|                  0|       false|     false|       false|2024-11-05 17:22:24|2024-12-27 20:00:...|\n",
      "|  2|566a6389-5c22-49c...|                  0|                  0|       false|     false|       false|2024-11-11 15:41:13|2024-12-27 20:00:...|\n",
      "|  3|64f0f28c-bedc-42d...|                  0|                102|       false|     false|       false|2024-12-27 16:05:08|2024-12-27 20:00:...|\n",
      "|  4|66de85d2-0aca-11e...|                 27|                 17|        true|      true|        true|2024-12-27 19:57:08|2024-12-27 20:00:...|\n",
      "|  5|29ced315-14b5-4ed...|                 30|                 14|        true|      true|        true|2024-12-27 19:57:07|2024-12-27 20:00:...|\n",
      "+---+--------------------+-------------------+-------------------+------------+----------+------------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 15:57:42 INFO CodeGenerator: Code generated in 19.80375 ms\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T14:58:56.386419Z",
     "start_time": "2025-01-02T14:58:56.190337Z"
    }
   },
   "cell_type": "code",
   "source": "df_station_info.show(5)",
   "id": "fe1c441d4b7a09ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+----------+---------+----------+---------+--------+------------------------+---------+---------+--------------------+--------------------+--------------------+\n",
      "|  id|          station_id|                name|short_name|      lat|       lon|region_id|capacity|eightd_has_key_dispenser|has_kiosk|installed|       last_reported|          created_at|          updated_at|\n",
      "+----+--------------------+--------------------+----------+---------+----------+---------+--------+------------------------+---------+---------+--------------------+--------------------+--------------------+\n",
      "| 643|1198e739-787c-4ce...|     7 Ave & W 55 St|   6847.05|40.764126|-73.980973|       71|      67|                   false|     true|    false|2024-12-30 14:21:...|2024-12-29 11:03:...|2024-12-30 14:21:...|\n",
      "|1255| 1885442082749874736|Grand Concourse &...|   8340.01| 40.84761| -73.90745|       71|      22|                   false|     true|    false|2024-12-30 14:21:...|2024-12-29 11:03:...|2024-12-30 14:21:...|\n",
      "| 258| 1862008939006380034|E 189 St & Bathga...|   8505.08| 40.85859| -73.88821|       71|      21|                   false|     true|    false|2024-12-30 14:21:...|2024-12-29 11:03:...|2024-12-30 14:21:...|\n",
      "| 426|754ac5df-f2b5-463...|Bailey Ave & Sedg...|   8643.01| 40.86571| -73.90857|       71|      20|                   false|     true|    false|2024-12-30 14:21:...|2024-12-29 11:03:...|2024-12-30 14:21:...|\n",
      "| 425| 1860188747953293684|Southern Blvd & E...|   8325.08| 40.84605| -73.88426|       71|      19|                   false|     true|    false|2024-12-30 14:21:...|2024-12-29 11:03:...|2024-12-30 14:21:...|\n",
      "+----+--------------------+--------------------+----------+---------+----------+---------+--------+------------------------+---------+---------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 15:58:56 INFO CodeGenerator: Code generated in 19.840334 ms\n",
      "25/01/02 15:58:56 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "25/01/02 15:58:56 INFO DAGScheduler: Got job 1 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/01/02 15:58:56 INFO DAGScheduler: Final stage: ResultStage 1 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/01/02 15:58:56 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/01/02 15:58:56 INFO DAGScheduler: Missing parents: List()\n",
      "25/01/02 15:58:56 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/01/02 15:58:56 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 18.0 KiB, free 6.2 GiB)\n",
      "25/01/02 15:58:56 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 6.2 GiB)\n",
      "25/01/02 15:58:56 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on macbookpro.fritz.box:53671 (size: 7.8 KiB, free: 6.2 GiB)\n",
      "25/01/02 15:58:56 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585\n",
      "25/01/02 15:58:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/01/02 15:58:56 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0\n",
      "25/01/02 15:58:56 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (macbookpro.fritz.box, executor driver, partition 0, PROCESS_LOCAL, 9033 bytes) \n",
      "25/01/02 15:58:56 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)\n",
      "25/01/02 15:58:56 INFO CodeGenerator: Code generated in 11.534334 ms\n",
      "25/01/02 15:58:56 INFO JDBCRDD: closed connection\n",
      "25/01/02 15:58:56 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2652 bytes result sent to driver\n",
      "25/01/02 15:58:56 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 75 ms on macbookpro.fritz.box (executor driver) (1/1)\n",
      "25/01/02 15:58:56 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "25/01/02 15:58:56 INFO DAGScheduler: ResultStage 1 (showString at NativeMethodAccessorImpl.java:0) finished in 0,085 s\n",
      "25/01/02 15:58:56 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/01/02 15:58:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished\n",
      "25/01/02 15:58:56 INFO DAGScheduler: Job 1 finished: showString at NativeMethodAccessorImpl.java:0, took 0,088451 s\n",
      "25/01/02 15:58:56 INFO CodeGenerator: Code generated in 10.904083 ms\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T15:05:37.483231Z",
     "start_time": "2025-01-02T15:05:33.287406Z"
    }
   },
   "cell_type": "code",
   "source": "df_tripdata.show(5)",
   "id": "fab5eddf6d03fc0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 16:05:33 INFO CodeGenerator: Code generated in 16.3335 ms\n",
      "25/01/02 16:05:33 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "25/01/02 16:05:33 INFO DAGScheduler: Got job 2 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/01/02 16:05:33 INFO DAGScheduler: Final stage: ResultStage 2 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/01/02 16:05:33 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/01/02 16:05:33 INFO DAGScheduler: Missing parents: List()\n",
      "25/01/02 16:05:33 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[8] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/01/02 16:05:33 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 18.2 KiB, free 6.2 GiB)\n",
      "25/01/02 16:05:33 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 6.2 GiB)\n",
      "25/01/02 16:05:33 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on macbookpro.fritz.box:53671 (size: 7.9 KiB, free: 6.2 GiB)\n",
      "25/01/02 16:05:33 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585\n",
      "25/01/02 16:05:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/01/02 16:05:33 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0\n",
      "25/01/02 16:05:33 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (macbookpro.fritz.box, executor driver, partition 0, PROCESS_LOCAL, 9033 bytes) \n",
      "25/01/02 16:05:33 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)\n",
      "25/01/02 16:05:33 INFO BlockManagerInfo: Removed broadcast_1_piece0 on macbookpro.fritz.box:53671 in memory (size: 7.8 KiB, free: 6.2 GiB)\n",
      "25/01/02 16:05:36 INFO BlockManagerInfo: Removed broadcast_0_piece0 on macbookpro.fritz.box:53671 in memory (size: 7.3 KiB, free: 6.2 GiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+-------------------+-------------------+--------------------+----------------+--------------------+--------------+---------+----------+---------+----------+-------------+----------+\n",
      "|         ride_id|rideable_type|         started_at|           ended_at|  start_station_name|start_station_id|    end_station_name|end_station_id|start_lat| start_lng|  end_lat|   end_lng|member_casual|     month|\n",
      "+----------------+-------------+-------------------+-------------------+--------------------+----------------+--------------------+--------------+---------+----------+---------+----------+-------------+----------+\n",
      "|3F874FD7056276BA|electric_bike|2024-10-31 00:00:00|2024-11-01 00:00:00|    W 30 St & 10 Ave|         6459.07|Cleveland Pl & Sp...|       5492.05|40.752694|-74.002353|40.722104|-73.997249|       member|2024-10-01|\n",
      "|E4FE320A5D6A8901| classic_bike|2024-10-31 00:00:00|2024-11-01 00:00:00|Sullivan St & Was...|         5721.01|Cleveland Pl & Sp...|       5492.05|40.730477|-73.999061|40.722104|-73.997249|       casual|2024-10-01|\n",
      "|D9B974903E41D0C6|electric_bike|2024-10-31 00:00:00|2024-11-01 00:00:00|Sullivan St & Was...|         5721.01|Cleveland Pl & Sp...|       5492.05|40.730477|-73.999061|40.722104|-73.997249|       casual|2024-10-01|\n",
      "|35AE372A27FAE5AC|electric_bike|2024-10-31 00:00:00|2024-11-01 00:00:00|     E 88 St & 1 Ave|         7235.13|     6 Ave & W 34 St|        6364.1|40.778301|-73.948813|40.749640|-73.988050|       member|2024-10-01|\n",
      "|DF9352DCAA03696C|electric_bike|2024-10-31 00:00:00|2024-11-01 00:00:00| W 12 St & Hudson St|         5997.10|Cleveland Pl & Sp...|       5492.05|40.737530|-74.005589|40.722104|-73.997249|       member|2024-10-01|\n",
      "+----------------+-------------+-------------------+-------------------+--------------------+----------------+--------------------+--------------+---------+----------+---------+----------+-------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 16:05:37 INFO CodeGenerator: Code generated in 10.747166 ms\n",
      "25/01/02 16:05:37 INFO JDBCRDD: closed connection\n",
      "25/01/02 16:05:37 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2430 bytes result sent to driver\n",
      "25/01/02 16:05:37 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 4072 ms on macbookpro.fritz.box (executor driver) (1/1)\n",
      "25/01/02 16:05:37 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "25/01/02 16:05:37 INFO DAGScheduler: ResultStage 2 (showString at NativeMethodAccessorImpl.java:0) finished in 4,081 s\n",
      "25/01/02 16:05:37 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/01/02 16:05:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished\n",
      "25/01/02 16:05:37 INFO DAGScheduler: Job 2 finished: showString at NativeMethodAccessorImpl.java:0, took 4,084026 s\n",
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T15:19:08.201802Z",
     "start_time": "2025-01-02T15:19:08.002622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "station_info_df = spark.read \\\n",
    "    .jdbc(url=jdbc_url, table=\"station_information\", properties=connection_properties) \\\n",
    "    .select(\"station_id\",\n",
    "            \"name\",\n",
    "            \"short_name\",\n",
    "            \"lat\",\n",
    "            \"lon\",\n",
    "            \"region_id\",\n",
    "            \"capacity\",\n",
    "            \"eightd_has_key_dispenser\",\n",
    "            \"has_kiosk\",\n",
    "            \"installed\",\n",
    "            \"last_reported\", \"created_at\", \"updated_at\"\n",
    "            ) \\\n",
    "            .cache()"
   ],
   "id": "ca094a3c4a129852",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T16:54:15.682115Z",
     "start_time": "2025-01-02T16:54:15.579659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "station_status_df = spark.read \\\n",
    "    .jdbc(url=jdbc_url, table=\"station_status\", properties=connection_properties) \\\n",
    "    .select(\"station_id\", \"num_bikes_available\", \"num_docks_available\", \"is_installed\", \"is_renting\", \"is_returning\", \"last_reported\", \"inserted_at\")\n",
    "station_status_df = station_status_df.withColumnRenamed(\"last_reported\", \"status_last_reported\")"
   ],
   "id": "976086140114739b",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T16:54:17.307853Z",
     "start_time": "2025-01-02T16:54:17.291208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "joined_df = station_status_df.join(\n",
    "    station_info_df,\n",
    "    on=\"station_id\",\n",
    "    how=\"inner\")"
   ],
   "id": "4b101d57abccb45e",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T16:54:22.125883Z",
     "start_time": "2025-01-02T16:54:19.806337Z"
    }
   },
   "cell_type": "code",
   "source": "joined_df.show(5)",
   "id": "65d9f38cfb86bfcb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 17:54:19 INFO DefaultCachedBatchSerializer: Predicate isnotnull(station_id#226) generates partition filter: ((station_id.count#2076 - station_id.nullCount#2075) > 0)\n",
      "25/01/02 17:54:19 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "25/01/02 17:54:19 INFO DAGScheduler: Got job 11 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions\n",
      "25/01/02 17:54:19 INFO DAGScheduler: Final stage: ResultStage 12 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)\n",
      "25/01/02 17:54:19 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/01/02 17:54:19 INFO DAGScheduler: Missing parents: List()\n",
      "25/01/02 17:54:19 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[55] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents\n",
      "25/01/02 17:54:19 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 35.6 KiB, free 6.0 GiB)\n",
      "25/01/02 17:54:19 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 6.0 GiB)\n",
      "25/01/02 17:54:19 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on macbookpro.fritz.box:53671 (size: 14.9 KiB, free: 6.2 GiB)\n",
      "25/01/02 17:54:19 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1585\n",
      "25/01/02 17:54:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[55] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))\n",
      "25/01/02 17:54:19 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0\n",
      "25/01/02 17:54:19 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 11) (macbookpro.fritz.box, executor driver, partition 0, PROCESS_LOCAL, 9033 bytes) \n",
      "25/01/02 17:54:19 INFO Executor: Running task 0.0 in stage 12.0 (TID 11)\n",
      "25/01/02 17:54:19 INFO BlockManager: Found block rdd_15_0 locally\n",
      "25/01/02 17:54:19 INFO Executor: Finished task 0.0 in stage 12.0 (TID 11). 213868 bytes result sent to driver\n",
      "25/01/02 17:54:19 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 11) in 14 ms on macbookpro.fritz.box (executor driver) (1/1)\n",
      "25/01/02 17:54:19 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool \n",
      "25/01/02 17:54:19 INFO DAGScheduler: ResultStage 12 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,019 s\n",
      "25/01/02 17:54:19 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/01/02 17:54:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished\n",
      "25/01/02 17:54:19 INFO DAGScheduler: Job 11 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,024899 s\n",
      "25/01/02 17:54:19 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 64.1 MiB, free 5.9 GiB)\n",
      "25/01/02 17:54:19 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 229.1 KiB, free 5.9 GiB)\n",
      "25/01/02 17:54:19 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on macbookpro.fritz.box:53671 (size: 229.1 KiB, free: 6.2 GiB)\n",
      "25/01/02 17:54:19 INFO SparkContext: Created broadcast 15 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "25/01/02 17:54:19 INFO CodeGenerator: Code generated in 15.635292 ms\n",
      "25/01/02 17:54:19 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "25/01/02 17:54:19 INFO DAGScheduler: Got job 12 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/01/02 17:54:19 INFO DAGScheduler: Final stage: ResultStage 13 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/01/02 17:54:19 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/01/02 17:54:19 INFO DAGScheduler: Missing parents: List()\n",
      "25/01/02 17:54:19 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[58] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/01/02 17:54:19 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 22.7 KiB, free 5.9 GiB)\n",
      "25/01/02 17:54:19 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 9.4 KiB, free 5.9 GiB)\n",
      "25/01/02 17:54:19 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on macbookpro.fritz.box:53671 (size: 9.4 KiB, free: 6.2 GiB)\n",
      "25/01/02 17:54:19 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1585\n",
      "25/01/02 17:54:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[58] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/01/02 17:54:19 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0\n",
      "25/01/02 17:54:19 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 12) (macbookpro.fritz.box, executor driver, partition 0, PROCESS_LOCAL, 9033 bytes) \n",
      "25/01/02 17:54:19 INFO Executor: Running task 0.0 in stage 13.0 (TID 12)\n",
      "25/01/02 17:54:21 INFO BlockManagerInfo: Removed broadcast_8_piece0 on macbookpro.fritz.box:53671 in memory (size: 173.9 KiB, free: 6.2 GiB)\n",
      "25/01/02 17:54:21 INFO BlockManagerInfo: Removed broadcast_10_piece0 on macbookpro.fritz.box:53671 in memory (size: 30.4 KiB, free: 6.2 GiB)\n",
      "25/01/02 17:54:21 INFO BlockManagerInfo: Removed broadcast_12_piece0 on macbookpro.fritz.box:53671 in memory (size: 229.1 KiB, free: 6.2 GiB)\n",
      "25/01/02 17:54:21 INFO BlockManagerInfo: Removed broadcast_11_piece0 on macbookpro.fritz.box:53671 in memory (size: 14.9 KiB, free: 6.2 GiB)\n",
      "25/01/02 17:54:21 INFO BlockManagerInfo: Removed broadcast_13_piece0 on macbookpro.fritz.box:53671 in memory (size: 9.4 KiB, free: 6.2 GiB)\n",
      "25/01/02 17:54:21 INFO BlockManagerInfo: Removed broadcast_14_piece0 on macbookpro.fritz.box:53671 in memory (size: 14.9 KiB, free: 6.2 GiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+----------+------------+--------------------+--------------------+--------------------+----------+-----------------+------------------+---------+--------+------------------------+---------+---------+--------------------+--------------------+--------------------+\n",
      "|          station_id|num_bikes_available|num_docks_available|is_installed|is_renting|is_returning|status_last_reported|         inserted_at|                name|short_name|              lat|               lon|region_id|capacity|eightd_has_key_dispenser|has_kiosk|installed|       last_reported|          created_at|          updated_at|\n",
      "+--------------------+-------------------+-------------------+------------+----------+------------+--------------------+--------------------+--------------------+----------+-----------------+------------------+---------+--------+------------------------+---------+---------+--------------------+--------------------+--------------------+\n",
      "|816e50eb-dc4b-47d...|                  0|                  0|       false|     false|       false| 2024-11-05 17:22:24|2024-12-27 20:00:...|       52 St & 6 Ave|   3084.05|        40.642703|        -74.009441|       71|      19|                   false|     true|    false|2024-12-30 14:21:...|2024-12-29 11:03:...|2024-12-30 14:21:...|\n",
      "|566a6389-5c22-49c...|                  0|                  0|       false|     false|       false| 2024-11-11 15:41:13|2024-12-27 20:00:...|       55 St & 5 Ave|   3050.03|        40.642408|        -74.013318|       71|       3|                   false|     true|    false|2024-12-30 14:21:...|2024-12-29 11:03:...|2024-12-30 14:21:...|\n",
      "|64f0f28c-bedc-42d...|                  0|                102|       false|     false|       false| 2024-12-27 16:05:08|2024-12-27 20:00:...|  Broadway & W 48 St|   6708.04|40.76017739537783|-73.98486793041229|       71|     103|                   false|     true|    false|2024-12-30 14:21:...|2024-12-29 11:03:...|2024-12-30 14:21:...|\n",
      "|66de85d2-0aca-11e...|                 27|                 17|        true|      true|        true| 2024-12-27 19:57:08|2024-12-27 20:00:...|Grand St & Elizab...|   5382.06|        40.718822|         -73.99596|       71|      45|                   false|     true|    false|2024-12-30 14:21:...|2024-12-29 11:03:...|2024-12-30 14:21:...|\n",
      "|29ced315-14b5-4ed...|                 30|                 14|        true|      true|        true| 2024-12-27 19:57:07|2024-12-27 20:00:...| W 12 St & Hudson St|   5997.10|40.73752993301071|-74.00558933615685|       71|      45|                   false|     true|    false|2024-12-30 14:21:...|2024-12-29 11:03:...|2024-12-30 14:21:...|\n",
      "+--------------------+-------------------+-------------------+------------+----------+------------+--------------------+--------------------+--------------------+----------+-----------------+------------------+---------+--------+------------------------+---------+---------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 17:54:22 INFO CodeGenerator: Code generated in 7.949458 ms\n",
      "25/01/02 17:54:22 INFO JDBCRDD: closed connection\n",
      "25/01/02 17:54:22 INFO Executor: Finished task 0.0 in stage 13.0 (TID 12). 2980 bytes result sent to driver\n",
      "25/01/02 17:54:22 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 12) in 2146 ms on macbookpro.fritz.box (executor driver) (1/1)\n",
      "25/01/02 17:54:22 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool \n",
      "25/01/02 17:54:22 INFO DAGScheduler: ResultStage 13 (showString at NativeMethodAccessorImpl.java:0) finished in 2,150 s\n",
      "25/01/02 17:54:22 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/01/02 17:54:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished\n",
      "25/01/02 17:54:22 INFO DAGScheduler: Job 12 finished: showString at NativeMethodAccessorImpl.java:0, took 2,152380 s\n",
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T17:16:26.591064Z",
     "start_time": "2025-01-02T17:16:26.497432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql.functions import avg, col, to_date, max as spark_max\n",
    "\n",
    "aggregated_df = joined_df.groupBy(\"station_id\", \"name\", \"short_name\", \"region_id\", \"lat\", \"lon\", \"capacity\", \"has_kiosk\", \"installed\", \"is_installed\", \"is_returning\", \"is_renting\", ) \\\n",
    "    .agg(\n",
    "        avg(\"num_bikes_available\").alias(\"avg_bikes_available\"),\n",
    "        avg(\"num_docks_available\").alias(\"avg_docks_available\"),\n",
    "        spark_max(\"status_last_reported\").alias(\"status_last_reported\"),\n",
    "        spark_max(\"last_reported\").alias(\"info_last_reported\")\n",
    ")\n",
    "aggregated_df = aggregated_df.withColumn(\n",
    "    \"aggregation_date\", to_date(col(\"status_last_reported\"))\n",
    ")"
   ],
   "id": "4fa7cfbe84d2339",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T17:16:32.225498Z",
     "start_time": "2025-01-02T17:16:28.634466Z"
    }
   },
   "cell_type": "code",
   "source": "aggregated_df.show(5)",
   "id": "7efff13e0c2f2a06",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 18:16:28 INFO CodeGenerator: Code generated in 6.916125 ms\n",
      "25/01/02 18:16:28 INFO DefaultCachedBatchSerializer: Predicate isnotnull(station_id#226) generates partition filter: ((station_id.count#3811 - station_id.nullCount#3810) > 0)\n",
      "25/01/02 18:16:28 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "25/01/02 18:16:28 INFO DAGScheduler: Got job 23 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions\n",
      "25/01/02 18:16:28 INFO DAGScheduler: Final stage: ResultStage 29 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)\n",
      "25/01/02 18:16:28 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/01/02 18:16:28 INFO DAGScheduler: Missing parents: List()\n",
      "25/01/02 18:16:28 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[107] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents\n",
      "25/01/02 18:16:28 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 34.6 KiB, free 6.1 GiB)\n",
      "25/01/02 18:16:28 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 6.1 GiB)\n",
      "25/01/02 18:16:28 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on macbookpro.fritz.box:53671 (size: 14.7 KiB, free: 6.2 GiB)\n",
      "25/01/02 18:16:28 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1585\n",
      "25/01/02 18:16:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[107] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))\n",
      "25/01/02 18:16:28 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0\n",
      "25/01/02 18:16:28 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 23) (macbookpro.fritz.box, executor driver, partition 0, PROCESS_LOCAL, 9033 bytes) \n",
      "25/01/02 18:16:28 INFO Executor: Running task 0.0 in stage 29.0 (TID 23)\n",
      "25/01/02 18:16:28 INFO BlockManager: Found block rdd_15_0 locally\n",
      "25/01/02 18:16:28 INFO CodeGenerator: Code generated in 6.589458 ms\n",
      "25/01/02 18:16:28 INFO CodeGenerator: Code generated in 3.139542 ms\n",
      "25/01/02 18:16:28 INFO Executor: Finished task 0.0 in stage 29.0 (TID 23). 204654 bytes result sent to driver\n",
      "25/01/02 18:16:28 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 23) in 25 ms on macbookpro.fritz.box (executor driver) (1/1)\n",
      "25/01/02 18:16:28 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool \n",
      "25/01/02 18:16:28 INFO DAGScheduler: ResultStage 29 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,038 s\n",
      "25/01/02 18:16:28 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/01/02 18:16:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished\n",
      "25/01/02 18:16:28 INFO DAGScheduler: Job 23 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,040160 s\n",
      "25/01/02 18:16:28 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 64.1 MiB, free 6.0 GiB)\n",
      "25/01/02 18:16:28 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 220.0 KiB, free 6.0 GiB)\n",
      "25/01/02 18:16:28 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on macbookpro.fritz.box:53671 (size: 220.0 KiB, free: 6.2 GiB)\n",
      "25/01/02 18:16:28 INFO SparkContext: Created broadcast 31 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "25/01/02 18:16:28 INFO CodeGenerator: Code generated in 21.877417 ms\n",
      "25/01/02 18:16:28 INFO DAGScheduler: Registering RDD 110 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 6\n",
      "25/01/02 18:16:28 INFO DAGScheduler: Got map stage job 24 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/01/02 18:16:28 INFO DAGScheduler: Final stage: ShuffleMapStage 30 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/01/02 18:16:28 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/01/02 18:16:28 INFO DAGScheduler: Missing parents: List()\n",
      "25/01/02 18:16:28 INFO DAGScheduler: Submitting ShuffleMapStage 30 (MapPartitionsRDD[110] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/01/02 18:16:28 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 83.8 KiB, free 6.0 GiB)\n",
      "25/01/02 18:16:28 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 33.7 KiB, free 6.0 GiB)\n",
      "25/01/02 18:16:28 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on macbookpro.fritz.box:53671 (size: 33.7 KiB, free: 6.2 GiB)\n",
      "25/01/02 18:16:28 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1585\n",
      "25/01/02 18:16:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[110] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/01/02 18:16:28 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0\n",
      "25/01/02 18:16:28 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 24) (macbookpro.fritz.box, executor driver, partition 0, PROCESS_LOCAL, 9022 bytes) \n",
      "25/01/02 18:16:28 INFO Executor: Running task 0.0 in stage 30.0 (TID 24)\n",
      "25/01/02 18:16:29 INFO BlockManagerInfo: Removed broadcast_30_piece0 on macbookpro.fritz.box:53671 in memory (size: 14.7 KiB, free: 6.2 GiB)\n",
      "25/01/02 18:16:30 INFO CodeGenerator: Code generated in 28.815792 ms\n",
      "25/01/02 18:16:30 INFO CodeGenerator: Code generated in 4.055833 ms\n",
      "25/01/02 18:16:30 INFO CodeGenerator: Code generated in 3.096667 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+---------+----------+------------+--------+---------+---------+------------+------------+----------+-------------------+-------------------+--------------------+--------------------+----------------+\n",
      "|          station_id|                name|short_name|region_id|       lat|         lon|capacity|has_kiosk|installed|is_installed|is_returning|is_renting|avg_bikes_available|avg_docks_available|status_last_reported|  info_last_reported|aggregation_date|\n",
      "+--------------------+--------------------+----------+---------+----------+------------+--------+---------+---------+------------+------------+----------+-------------------+-------------------+--------------------+--------------------+----------------+\n",
      "|66dd4c5f-0aca-11e...|Columbus Ave & W ...|   7175.05|       71|40.7770575|-73.97898475|      67|     true|    false|        true|        true|      true| 39.724425887265134| 23.748434237995824| 2025-01-02 17:14:34|2024-12-30 14:21:...|      2025-01-02|\n",
      "|62e2b1dd-ca52-4e1...|Greenwood Ave & E...|   3353.04|       71| 40.650739|  -73.977739|      21|     true|    false|        true|        true|      true| 15.393528183716075|  4.760960334029227| 2025-01-02 17:13:55|2024-12-30 14:21:...|      2025-01-02|\n",
      "|8d2eff37-be09-4b4...|       3 Ave & 17 St|   3779.02|       71| 40.666168|  -73.995549|      21|     true|    false|        true|        true|      true| 14.961377870563675| 3.4676409185803756| 2025-01-02 17:13:44|2024-12-30 14:21:...|      2025-01-02|\n",
      "| 1958457675193833900|    1 Ave & E 118 St|   7596.11|       71| 40.797459|  -73.934499|      24|     true|    false|        true|        true|      true|  14.81123595505618|  8.895505617977529| 2025-01-02 17:15:08|2024-12-30 14:21:...|      2025-01-02|\n",
      "| 1828965671716082498|Cortelyou Rd & E ...|   3087.01|       71|  40.64454|   -73.94486|      19|     true|    false|        true|        true|      true| 17.058455114822547| 0.7797494780793319| 2025-01-02 17:15:21|2024-12-30 14:21:...|      2025-01-02|\n",
      "+--------------------+--------------------+----------+---------+----------+------------+--------+---------+---------+------------+------------+----------+-------------------+-------------------+--------------------+--------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 18:16:32 INFO JDBCRDD: closed connection\n",
      "25/01/02 18:16:32 INFO Executor: Finished task 0.0 in stage 30.0 (TID 24). 3301 bytes result sent to driver\n",
      "25/01/02 18:16:32 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 24) in 3280 ms on macbookpro.fritz.box (executor driver) (1/1)\n",
      "25/01/02 18:16:32 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool \n",
      "25/01/02 18:16:32 INFO DAGScheduler: ShuffleMapStage 30 (showString at NativeMethodAccessorImpl.java:0) finished in 3,286 s\n",
      "25/01/02 18:16:32 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/01/02 18:16:32 INFO DAGScheduler: running: Set()\n",
      "25/01/02 18:16:32 INFO DAGScheduler: waiting: Set()\n",
      "25/01/02 18:16:32 INFO DAGScheduler: failed: Set()\n",
      "25/01/02 18:16:32 INFO ShufflePartitionsUtil: For shuffle(6), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/01/02 18:16:32 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/01/02 18:16:32 INFO CodeGenerator: Code generated in 8.816125 ms\n",
      "25/01/02 18:16:32 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "25/01/02 18:16:32 INFO DAGScheduler: Got job 25 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/01/02 18:16:32 INFO DAGScheduler: Final stage: ResultStage 32 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/01/02 18:16:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)\n",
      "25/01/02 18:16:32 INFO DAGScheduler: Missing parents: List()\n",
      "25/01/02 18:16:32 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[113] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/01/02 18:16:32 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 91.1 KiB, free 6.0 GiB)\n",
      "25/01/02 18:16:32 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 6.0 GiB)\n",
      "25/01/02 18:16:32 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on macbookpro.fritz.box:53671 (size: 35.4 KiB, free: 6.2 GiB)\n",
      "25/01/02 18:16:32 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1585\n",
      "25/01/02 18:16:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[113] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/01/02 18:16:32 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0\n",
      "25/01/02 18:16:32 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 25) (macbookpro.fritz.box, executor driver, partition 0, NODE_LOCAL, 9187 bytes) \n",
      "25/01/02 18:16:32 INFO Executor: Running task 0.0 in stage 32.0 (TID 25)\n",
      "25/01/02 18:16:32 INFO ShuffleBlockFetcherIterator: Getting 1 (328.4 KiB) non-empty blocks including 1 (328.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/01/02 18:16:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/01/02 18:16:32 INFO CodeGenerator: Code generated in 8.318 ms\n",
      "25/01/02 18:16:32 INFO Executor: Finished task 0.0 in stage 32.0 (TID 25). 7075 bytes result sent to driver\n",
      "25/01/02 18:16:32 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 25) in 24 ms on macbookpro.fritz.box (executor driver) (1/1)\n",
      "25/01/02 18:16:32 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool \n",
      "25/01/02 18:16:32 INFO DAGScheduler: ResultStage 32 (showString at NativeMethodAccessorImpl.java:0) finished in 0,027 s\n",
      "25/01/02 18:16:32 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/01/02 18:16:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished\n",
      "25/01/02 18:16:32 INFO DAGScheduler: Job 25 finished: showString at NativeMethodAccessorImpl.java:0, took 0,029335 s\n",
      "25/01/02 18:16:32 INFO CodeGenerator: Code generated in 3.090417 ms             \n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T18:30:23.006208Z",
     "start_time": "2025-01-02T18:30:22.931592Z"
    }
   },
   "cell_type": "code",
   "source": "aggregated_df.createOrReplaceTempView(\"station_status_transformed\")",
   "id": "556a14e862d48219",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T18:30:25.029616Z",
     "start_time": "2025-01-02T18:30:25.018249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dim_station_status = spark.sql(\"\"\"\n",
    "                               select count(*) as total_records\n",
    "                               from station_status_transformed\n",
    "                               \"\"\")"
   ],
   "id": "49772f4f8911f26d",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T18:30:33.343749Z",
     "start_time": "2025-01-02T18:30:28.032714Z"
    }
   },
   "cell_type": "code",
   "source": "dim_station_status.show()",
   "id": "9c6af07a5b1791be",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 19:30:28 INFO CodeGenerator: Code generated in 7.99125 ms\n",
      "25/01/02 19:30:28 INFO DefaultCachedBatchSerializer: Predicate isnotnull(station_id#226) generates partition filter: ((station_id.count#4158 - station_id.nullCount#4157) > 0)\n",
      "25/01/02 19:30:28 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "25/01/02 19:30:28 INFO DAGScheduler: Got job 26 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions\n",
      "25/01/02 19:30:28 INFO DAGScheduler: Final stage: ResultStage 33 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)\n",
      "25/01/02 19:30:28 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/01/02 19:30:28 INFO DAGScheduler: Missing parents: List()\n",
      "25/01/02 19:30:28 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[120] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents\n",
      "25/01/02 19:30:28 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 34.3 KiB, free 6.1 GiB)\n",
      "25/01/02 19:30:28 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 6.1 GiB)\n",
      "25/01/02 19:30:28 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on macbookpro.fritz.box:53671 (size: 14.7 KiB, free: 6.2 GiB)\n",
      "25/01/02 19:30:28 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1585\n",
      "25/01/02 19:30:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[120] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))\n",
      "25/01/02 19:30:28 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0\n",
      "25/01/02 19:30:28 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 26) (macbookpro.fritz.box, executor driver, partition 0, PROCESS_LOCAL, 9033 bytes) \n",
      "25/01/02 19:30:28 INFO Executor: Running task 0.0 in stage 33.0 (TID 26)\n",
      "25/01/02 19:30:28 INFO BlockManager: Found block rdd_15_0 locally\n",
      "25/01/02 19:30:28 INFO CodeGenerator: Code generated in 10.338708 ms\n",
      "25/01/02 19:30:28 INFO CodeGenerator: Code generated in 6.98625 ms\n",
      "25/01/02 19:30:28 INFO Executor: Finished task 0.0 in stage 33.0 (TID 26). 194855 bytes result sent to driver\n",
      "25/01/02 19:30:28 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 26) in 65 ms on macbookpro.fritz.box (executor driver) (1/1)\n",
      "25/01/02 19:30:28 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool \n",
      "25/01/02 19:30:28 INFO DAGScheduler: ResultStage 33 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,081 s\n",
      "25/01/02 19:30:28 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/01/02 19:30:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 33: Stage finished\n",
      "25/01/02 19:30:28 INFO DAGScheduler: Job 26 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,084115 s\n",
      "25/01/02 19:30:28 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 64.1 MiB, free 6.0 GiB)\n",
      "25/01/02 19:30:28 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 211.1 KiB, free 6.0 GiB)\n",
      "25/01/02 19:30:28 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on macbookpro.fritz.box:53671 (size: 211.1 KiB, free: 6.2 GiB)\n",
      "25/01/02 19:30:28 INFO SparkContext: Created broadcast 35 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "25/01/02 19:30:28 INFO CodeGenerator: Code generated in 16.128916 ms\n",
      "25/01/02 19:30:28 INFO DAGScheduler: Registering RDD 123 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 7\n",
      "25/01/02 19:30:28 INFO DAGScheduler: Got map stage job 27 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/01/02 19:30:28 INFO DAGScheduler: Final stage: ShuffleMapStage 34 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/01/02 19:30:28 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/01/02 19:30:28 INFO DAGScheduler: Missing parents: List()\n",
      "25/01/02 19:30:28 INFO DAGScheduler: Submitting ShuffleMapStage 34 (MapPartitionsRDD[123] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/01/02 19:30:28 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 67.6 KiB, free 6.0 GiB)\n",
      "25/01/02 19:30:28 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 6.0 GiB)\n",
      "25/01/02 19:30:28 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on macbookpro.fritz.box:53671 (size: 27.9 KiB, free: 6.2 GiB)\n",
      "25/01/02 19:30:28 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1585\n",
      "25/01/02 19:30:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[123] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/01/02 19:30:28 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0\n",
      "25/01/02 19:30:28 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 27) (macbookpro.fritz.box, executor driver, partition 0, PROCESS_LOCAL, 9022 bytes) \n",
      "25/01/02 19:30:28 INFO Executor: Running task 0.0 in stage 34.0 (TID 27)\n",
      "25/01/02 19:30:30 INFO CodeGenerator: Code generated in 25.655958 ms(0 + 1) / 1]\n",
      "25/01/02 19:30:30 INFO BlockManagerInfo: Removed broadcast_34_piece0 on macbookpro.fritz.box:53671 in memory (size: 14.7 KiB, free: 6.2 GiB)\n",
      "25/01/02 19:30:33 INFO JDBCRDD: closed connection\n",
      "25/01/02 19:30:33 INFO Executor: Finished task 0.0 in stage 34.0 (TID 27). 3301 bytes result sent to driver\n",
      "25/01/02 19:30:33 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 27) in 4870 ms on macbookpro.fritz.box (executor driver) (1/1)\n",
      "25/01/02 19:30:33 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool \n",
      "25/01/02 19:30:33 INFO DAGScheduler: ShuffleMapStage 34 (showString at NativeMethodAccessorImpl.java:0) finished in 4,875 s\n",
      "25/01/02 19:30:33 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/01/02 19:30:33 INFO DAGScheduler: running: Set()\n",
      "25/01/02 19:30:33 INFO DAGScheduler: waiting: Set()\n",
      "25/01/02 19:30:33 INFO DAGScheduler: failed: Set()\n",
      "25/01/02 19:30:33 INFO ShufflePartitionsUtil: For shuffle(7), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/01/02 19:30:33 INFO CodeGenerator: Code generated in 31.169833 ms\n",
      "25/01/02 19:30:33 INFO DAGScheduler: Registering RDD 126 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 8\n",
      "25/01/02 19:30:33 INFO DAGScheduler: Got map stage job 28 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/01/02 19:30:33 INFO DAGScheduler: Final stage: ShuffleMapStage 36 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/01/02 19:30:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)\n",
      "25/01/02 19:30:33 INFO DAGScheduler: Missing parents: List()\n",
      "25/01/02 19:30:33 INFO DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[126] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/01/02 19:30:33 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 75.0 KiB, free 6.0 GiB)\n",
      "25/01/02 19:30:33 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 30.6 KiB, free 6.0 GiB)\n",
      "25/01/02 19:30:33 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on macbookpro.fritz.box:53671 (size: 30.6 KiB, free: 6.2 GiB)\n",
      "25/01/02 19:30:33 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1585\n",
      "25/01/02 19:30:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[126] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/01/02 19:30:33 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0\n",
      "25/01/02 19:30:33 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 28) (macbookpro.fritz.box, executor driver, partition 0, NODE_LOCAL, 9176 bytes) \n",
      "25/01/02 19:30:33 INFO Executor: Running task 0.0 in stage 36.0 (TID 28)\n",
      "25/01/02 19:30:33 INFO ShuffleBlockFetcherIterator: Getting 1 (269.1 KiB) non-empty blocks including 1 (269.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/01/02 19:30:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|total_records|\n",
      "+-------------+\n",
      "|         2372|\n",
      "+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 19:30:33 INFO CodeGenerator: Code generated in 29.357833 ms\n",
      "25/01/02 19:30:33 INFO Executor: Finished task 0.0 in stage 36.0 (TID 28). 6217 bytes result sent to driver\n",
      "25/01/02 19:30:33 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 28) in 64 ms on macbookpro.fritz.box (executor driver) (1/1)\n",
      "25/01/02 19:30:33 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool \n",
      "25/01/02 19:30:33 INFO DAGScheduler: ShuffleMapStage 36 (showString at NativeMethodAccessorImpl.java:0) finished in 0,069 s\n",
      "25/01/02 19:30:33 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/01/02 19:30:33 INFO DAGScheduler: running: Set()\n",
      "25/01/02 19:30:33 INFO DAGScheduler: waiting: Set()\n",
      "25/01/02 19:30:33 INFO DAGScheduler: failed: Set()\n",
      "25/01/02 19:30:33 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "25/01/02 19:30:33 INFO DAGScheduler: Got job 29 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/01/02 19:30:33 INFO DAGScheduler: Final stage: ResultStage 39 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/01/02 19:30:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 38)\n",
      "25/01/02 19:30:33 INFO DAGScheduler: Missing parents: List()\n",
      "25/01/02 19:30:33 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[129] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/01/02 19:30:33 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 12.6 KiB, free 6.0 GiB)\n",
      "25/01/02 19:30:33 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 6.0 GiB)\n",
      "25/01/02 19:30:33 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on macbookpro.fritz.box:53671 (size: 6.0 KiB, free: 6.2 GiB)\n",
      "25/01/02 19:30:33 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1585\n",
      "25/01/02 19:30:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[129] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/01/02 19:30:33 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0\n",
      "25/01/02 19:30:33 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 29) (macbookpro.fritz.box, executor driver, partition 0, NODE_LOCAL, 9187 bytes) \n",
      "25/01/02 19:30:33 INFO Executor: Running task 0.0 in stage 39.0 (TID 29)\n",
      "25/01/02 19:30:33 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/01/02 19:30:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/01/02 19:30:33 INFO Executor: Finished task 0.0 in stage 39.0 (TID 29). 4004 bytes result sent to driver\n",
      "25/01/02 19:30:33 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 29) in 6 ms on macbookpro.fritz.box (executor driver) (1/1)\n",
      "25/01/02 19:30:33 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool \n",
      "25/01/02 19:30:33 INFO DAGScheduler: ResultStage 39 (showString at NativeMethodAccessorImpl.java:0) finished in 0,010 s\n",
      "25/01/02 19:30:33 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/01/02 19:30:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 39: Stage finished\n",
      "25/01/02 19:30:33 INFO DAGScheduler: Job 29 finished: showString at NativeMethodAccessorImpl.java:0, took 0,014150 s\n",
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T18:30:33.416366Z",
     "start_time": "2025-01-02T18:30:33.410661Z"
    }
   },
   "cell_type": "code",
   "source": "aggregated_df.printSchema()",
   "id": "72b845b76283368e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- station_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- short_name: string (nullable = true)\n",
      " |-- region_id: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- lon: double (nullable = true)\n",
      " |-- capacity: integer (nullable = true)\n",
      " |-- has_kiosk: boolean (nullable = true)\n",
      " |-- installed: boolean (nullable = true)\n",
      " |-- is_installed: boolean (nullable = true)\n",
      " |-- is_returning: boolean (nullable = true)\n",
      " |-- is_renting: boolean (nullable = true)\n",
      " |-- avg_bikes_available: double (nullable = true)\n",
      " |-- avg_docks_available: double (nullable = true)\n",
      " |-- status_last_reported: timestamp (nullable = true)\n",
      " |-- info_last_reported: timestamp (nullable = true)\n",
      " |-- aggregation_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# station_status_transformed = \\\n",
    "# \"\"\"CREATE TABLE IF NOT EXISTS station_status_transformed (\n",
    "#     station_id VARCHAR(255),\n",
    "#     name VARCHAR(255),\n",
    "#     short_name VARCHAR(255),\n",
    "#     region_id VARCHAR(255),\n",
    "#     lat DECIMAL,\n",
    "#     lon DECIMAL,\n",
    "#     capacity INT,\n",
    "#     has_kiosk BOOLEAN,\n",
    "#     installed BOOLEAN,\n",
    "#     is_installed BOOLEAN,\n",
    "#     is_returning BOOLEAN,\n",
    "#     is_renting BOOLEAN,\n",
    "#     avg_bikes_available DECIMAL,\n",
    "#     avg_docks_available DECIMAL,\n",
    "#     status_last_reported TIMESTAMP,\n",
    "#     info_last_reported TIMESTAMP,\n",
    "#     aggregation_date DATE\n",
    "# ) PARTITION BY RANGE (aggregation_date);\n",
    "# \"\"\""
   ],
   "id": "752dc64cb9cbc1cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T18:42:41.797128Z",
     "start_time": "2025-01-02T18:42:34.081552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "aggregated_df.write \\\n",
    "    .jdbc(url=jdbc_url,\n",
    "          table=\"station_status_transformed\",\n",
    "          mode=\"append\",\n",
    "          properties=connection_properties\n",
    "          )"
   ],
   "id": "74edd1cbaf3087fe",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 19:42:34 INFO DefaultCachedBatchSerializer: Predicate isnotnull(station_id#226) generates partition filter: ((station_id.count#4914 - station_id.nullCount#4913) > 0)\n",
      "25/01/02 19:42:34 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "25/01/02 19:42:34 INFO DAGScheduler: Got job 33 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions\n",
      "25/01/02 19:42:34 INFO DAGScheduler: Final stage: ResultStage 44 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)\n",
      "25/01/02 19:42:34 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/01/02 19:42:34 INFO DAGScheduler: Missing parents: List()\n",
      "25/01/02 19:42:34 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[151] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents\n",
      "25/01/02 19:42:34 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 34.6 KiB, free 6.1 GiB)\n",
      "25/01/02 19:42:34 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 6.1 GiB)\n",
      "25/01/02 19:42:34 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on macbookpro.fritz.box:53671 (size: 14.7 KiB, free: 6.2 GiB)\n",
      "25/01/02 19:42:34 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1585\n",
      "25/01/02 19:42:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[151] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))\n",
      "25/01/02 19:42:34 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0\n",
      "25/01/02 19:42:34 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 33) (macbookpro.fritz.box, executor driver, partition 0, PROCESS_LOCAL, 9033 bytes) \n",
      "25/01/02 19:42:34 INFO Executor: Running task 0.0 in stage 44.0 (TID 33)\n",
      "25/01/02 19:42:34 INFO BlockManager: Found block rdd_15_0 locally\n",
      "25/01/02 19:42:34 INFO Executor: Finished task 0.0 in stage 44.0 (TID 33). 204611 bytes result sent to driver\n",
      "25/01/02 19:42:34 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 33) in 18 ms on macbookpro.fritz.box (executor driver) (1/1)\n",
      "25/01/02 19:42:34 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool \n",
      "25/01/02 19:42:34 INFO DAGScheduler: ResultStage 44 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,040 s\n",
      "25/01/02 19:42:34 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/01/02 19:42:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished\n",
      "25/01/02 19:42:34 INFO DAGScheduler: Job 33 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,042554 s\n",
      "25/01/02 19:42:34 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 64.1 MiB, free 6.0 GiB)\n",
      "25/01/02 19:42:34 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 220.0 KiB, free 6.0 GiB)\n",
      "25/01/02 19:42:34 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on macbookpro.fritz.box:53671 (size: 220.0 KiB, free: 6.2 GiB)\n",
      "25/01/02 19:42:34 INFO SparkContext: Created broadcast 44 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "25/01/02 19:42:34 INFO DAGScheduler: Registering RDD 154 (jdbc at NativeMethodAccessorImpl.java:0) as input to shuffle 10\n",
      "25/01/02 19:42:34 INFO DAGScheduler: Got map stage job 34 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/01/02 19:42:34 INFO DAGScheduler: Final stage: ShuffleMapStage 45 (jdbc at NativeMethodAccessorImpl.java:0)\n",
      "25/01/02 19:42:34 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/01/02 19:42:34 INFO DAGScheduler: Missing parents: List()\n",
      "25/01/02 19:42:34 INFO DAGScheduler: Submitting ShuffleMapStage 45 (MapPartitionsRDD[154] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/01/02 19:42:34 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 84.5 KiB, free 6.0 GiB)\n",
      "25/01/02 19:42:34 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 6.0 GiB)\n",
      "25/01/02 19:42:34 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on macbookpro.fritz.box:53671 (size: 33.8 KiB, free: 6.2 GiB)\n",
      "25/01/02 19:42:34 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1585\n",
      "25/01/02 19:42:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[154] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/01/02 19:42:34 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks resource profile 0\n",
      "25/01/02 19:42:34 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 34) (macbookpro.fritz.box, executor driver, partition 0, PROCESS_LOCAL, 9022 bytes) \n",
      "25/01/02 19:42:34 INFO Executor: Running task 0.0 in stage 45.0 (TID 34)\n",
      "25/01/02 19:42:36 INFO BlockManagerInfo: Removed broadcast_43_piece0 on macbookpro.fritz.box:53671 in memory (size: 14.7 KiB, free: 6.2 GiB)\n",
      "25/01/02 19:42:41 INFO JDBCRDD: closed connection\n",
      "25/01/02 19:42:41 INFO Executor: Finished task 0.0 in stage 45.0 (TID 34). 3344 bytes result sent to driver\n",
      "25/01/02 19:42:41 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 34) in 7024 ms on macbookpro.fritz.box (executor driver) (1/1)\n",
      "25/01/02 19:42:41 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool \n",
      "25/01/02 19:42:41 INFO DAGScheduler: ShuffleMapStage 45 (jdbc at NativeMethodAccessorImpl.java:0) finished in 7,031 s\n",
      "25/01/02 19:42:41 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/01/02 19:42:41 INFO DAGScheduler: running: Set()\n",
      "25/01/02 19:42:41 INFO DAGScheduler: waiting: Set()\n",
      "25/01/02 19:42:41 INFO DAGScheduler: failed: Set()\n",
      "25/01/02 19:42:41 INFO ShufflePartitionsUtil: For shuffle(10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/01/02 19:42:41 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/01/02 19:42:41 INFO SparkContext: Starting job: jdbc at NativeMethodAccessorImpl.java:0\n",
      "25/01/02 19:42:41 INFO DAGScheduler: Got job 35 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/01/02 19:42:41 INFO DAGScheduler: Final stage: ResultStage 47 (jdbc at NativeMethodAccessorImpl.java:0)\n",
      "25/01/02 19:42:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 46)\n",
      "25/01/02 19:42:41 INFO DAGScheduler: Missing parents: List()\n",
      "25/01/02 19:42:41 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[159] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/01/02 19:42:41 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 95.6 KiB, free 6.0 GiB)\n",
      "25/01/02 19:42:41 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 6.0 GiB)\n",
      "25/01/02 19:42:41 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on macbookpro.fritz.box:53671 (size: 37.3 KiB, free: 6.2 GiB)\n",
      "25/01/02 19:42:41 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1585\n",
      "25/01/02 19:42:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[159] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/01/02 19:42:41 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks resource profile 0\n",
      "25/01/02 19:42:41 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 35) (macbookpro.fritz.box, executor driver, partition 0, NODE_LOCAL, 9187 bytes) \n",
      "25/01/02 19:42:41 INFO Executor: Running task 0.0 in stage 47.0 (TID 35)\n",
      "25/01/02 19:42:41 INFO ShuffleBlockFetcherIterator: Getting 1 (330.4 KiB) non-empty blocks including 1 (330.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/01/02 19:42:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/01/02 19:42:41 INFO Executor: Finished task 0.0 in stage 47.0 (TID 35). 5454 bytes result sent to driver\n",
      "25/01/02 19:42:41 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 35) in 201 ms on macbookpro.fritz.box (executor driver) (1/1)\n",
      "25/01/02 19:42:41 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool \n",
      "25/01/02 19:42:41 INFO DAGScheduler: ResultStage 47 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0,218 s\n",
      "25/01/02 19:42:41 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/01/02 19:42:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished\n",
      "25/01/02 19:42:41 INFO DAGScheduler: Job 35 finished: jdbc at NativeMethodAccessorImpl.java:0, took 0,226597 s\n",
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T18:45:32.794086Z",
     "start_time": "2025-01-02T18:45:32.782592Z"
    }
   },
   "cell_type": "code",
   "source": "df_tripdata.printSchema()",
   "id": "9cf8549e011d42ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ride_id: string (nullable = true)\n",
      " |-- rideable_type: string (nullable = true)\n",
      " |-- started_at: timestamp (nullable = true)\n",
      " |-- ended_at: timestamp (nullable = true)\n",
      " |-- start_station_name: string (nullable = true)\n",
      " |-- start_station_id: string (nullable = true)\n",
      " |-- end_station_name: string (nullable = true)\n",
      " |-- end_station_id: string (nullable = true)\n",
      " |-- start_lat: decimal(9,6) (nullable = true)\n",
      " |-- start_lng: decimal(9,6) (nullable = true)\n",
      " |-- end_lat: decimal(9,6) (nullable = true)\n",
      " |-- end_lng: decimal(9,6) (nullable = true)\n",
      " |-- member_casual: string (nullable = true)\n",
      " |-- month: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T19:28:14.249431Z",
     "start_time": "2025-01-02T19:28:14.070356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tripdata_df = spark.read \\\n",
    "    .jdbc(url=jdbc_url, table=\"tripdata\", properties=connection_properties) \\\n",
    "    .select(\n",
    "        \"ride_id\", \"rideable_type\", \"started_at\", \"ended_at\", \"start_station_name\", \"start_station_id\", \"end_station_name\", \"end_station_id\", \"start_lat\", \"start_lng\", \"end_lat\", \"end_lng\", \"member_casual\", \"month\"\n",
    "            ) \\\n",
    "            .cache()\n",
    "\n",
    "tripdata_df = tripdata_df.withColumnRenamed(\"start_station_name\", \"original_start_station_name\") \\\n",
    "                         .withColumnRenamed(\"start_lat\", \"original_start_lat\") \\\n",
    "                         .withColumnRenamed(\"end_station_name\", \"original_end_station_name\") \\\n",
    "                         .withColumnRenamed(\"end_lat\", \"original_end_lat\")"
   ],
   "id": "50537f38b5cf16a2",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T18:47:54.557294Z",
     "start_time": "2025-01-02T18:47:54.531431Z"
    }
   },
   "cell_type": "code",
   "source": "aggregated_df.printSchema(5)",
   "id": "36dd2c96e394d771",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- station_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- short_name: string (nullable = true)\n",
      " |-- region_id: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- lon: double (nullable = true)\n",
      " |-- capacity: integer (nullable = true)\n",
      " |-- has_kiosk: boolean (nullable = true)\n",
      " |-- installed: boolean (nullable = true)\n",
      " |-- is_installed: boolean (nullable = true)\n",
      " |-- is_returning: boolean (nullable = true)\n",
      " |-- is_renting: boolean (nullable = true)\n",
      " |-- avg_bikes_available: double (nullable = true)\n",
      " |-- avg_docks_available: double (nullable = true)\n",
      " |-- status_last_reported: timestamp (nullable = true)\n",
      " |-- info_last_reported: timestamp (nullable = true)\n",
      " |-- aggregation_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T19:28:23.462909Z",
     "start_time": "2025-01-02T19:28:23.384181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transformed_station_status_df = spark.read \\\n",
    "    .jdbc(url=jdbc_url, table=\"station_status_transformed\", properties=connection_properties) \\\n",
    "        .select(\n",
    "            \"station_id\", \"name\", \"short_name\", \"region_id\", \"lat\", \"lon\", \"capacity\", \"has_kiosk\", \"installed\", \"is_installed\",           \"is_returning\", \"is_renting\", \"avg_bikes_available\", \"avg_docks_available\", \"status_last_reported\", \"info_last_reported\",      \"aggregation_date\")\\\n",
    "        .cache()"
   ],
   "id": "de635ac2a84bc446",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T19:28:38.434807Z",
     "start_time": "2025-01-02T19:28:38.357027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql.functions import col, broadcast\n",
    "\n",
    "# Rename columns for Start Station\n",
    "start_station_df = transformed_station_status_df.select(\n",
    "    col(\"short_name\").alias(\"start_station_short_name\"),\n",
    "    col(\"name\").alias(\"start_station_name\"),\n",
    "    col(\"lat\").alias(\"start_lat\"),\n",
    "    col(\"lon\").alias(\"start_lon\"),\n",
    "    col(\"capacity\").alias(\"start_capacity\"),\n",
    "    col(\"avg_bikes_available\").alias(\"start_avg_bikes_available\"),\n",
    "    col(\"avg_docks_available\").alias(\"start_avg_docks_available\"),\n",
    "    col(\"status_last_reported\").alias(\"start_status_last_reported\"),\n",
    "    col(\"info_last_reported\").alias(\"start_info_last_reported\")\n",
    ")\n",
    "\n",
    "# Rename columns for End Station\n",
    "end_station_df = transformed_station_status_df.select(\n",
    "    col(\"short_name\").alias(\"end_station_short_name\"),\n",
    "    col(\"name\").alias(\"end_station_name\"),\n",
    "    col(\"lat\").alias(\"end_lat\"),\n",
    "    col(\"lon\").alias(\"end_lon\"),\n",
    "    col(\"capacity\").alias(\"end_capacity\"),\n",
    "    col(\"avg_bikes_available\").alias(\"end_avg_bikes_available\"),\n",
    "    col(\"avg_docks_available\").alias(\"end_avg_docks_available\"),\n",
    "    col(\"status_last_reported\").alias(\"end_status_last_reported\"),\n",
    "    col(\"info_last_reported\").alias(\"end_info_last_reported\")\n",
    ")\n"
   ],
   "id": "21c965491c521576",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T19:28:42.431899Z",
     "start_time": "2025-01-02T19:28:42.422526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "# Broadcast Start and End Station DataFrames\n",
    "start_station_broadcast = broadcast(start_station_df)\n",
    "end_station_broadcast = broadcast(end_station_df)\n"
   ],
   "id": "680867aa856a1a31",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T19:28:45.095757Z",
     "start_time": "2025-01-02T19:28:45.072056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Join tripdata_df with Start Station Information\n",
    "trip_with_start = tripdata_df.join(\n",
    "    start_station_broadcast,\n",
    "    tripdata_df.start_station_id == start_station_broadcast.start_station_short_name,\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Join the result with End Station Information\n",
    "final_df = trip_with_start.join(\n",
    "    end_station_broadcast,\n",
    "    tripdata_df.end_station_id == end_station_broadcast.end_station_short_name,\n",
    "    how=\"left\"\n",
    ")"
   ],
   "id": "1daafac4d88819d9",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T19:01:42.875947Z",
     "start_time": "2025-01-02T19:01:22.537546Z"
    }
   },
   "cell_type": "code",
   "source": "trip_with_start.show(5)",
   "id": "6dad500bef7b0f4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 20:01:22 INFO CodeGenerator: Code generated in 16.601916 ms\n",
      "25/01/02 20:01:22 INFO DAGScheduler: Got job 36 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/01/02 20:01:22 INFO DAGScheduler: Final stage: ResultStage 48 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/01/02 20:01:22 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/01/02 20:01:22 INFO DAGScheduler: Missing parents: List()\n",
      "25/01/02 20:01:22 INFO DAGScheduler: Submitting ResultStage 48 (*(1) Scan JDBCRelation(tripdata) [numPartitions=1] [ride_id#5005,rideable_type#5006,started_at#5007,ended_at#5008,start_station_name#5009,start_station_id#5010,end_station_name#5011,end_station_id#5012,start_lat#5013,start_lng#5014,end_lat#5015,end_lng#5016,member_casual#5017,month#5018] PushedFilters: [], ReadSchema: struct<ride_id:string,rideable_type:string,started_at:timestamp,ended_at:timestamp,start_station_...\n",
      " MapPartitionsRDD[164] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/01/02 20:01:22 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 19.4 KiB, free 6.0 GiB)\n",
      "25/01/02 20:01:22 INFO CodeGenerator: Code generated in 22.393042 ms\n",
      "25/01/02 20:01:22 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 6.0 GiB)\n",
      "25/01/02 20:01:22 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on macbookpro.fritz.box:53671 (size: 8.7 KiB, free: 6.2 GiB)\n",
      "25/01/02 20:01:22 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1585\n",
      "25/01/02 20:01:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (*(1) Scan JDBCRelation(tripdata) [numPartitions=1] [ride_id#5005,rideable_type#5006,started_at#5007,ended_at#5008,start_station_name#5009,start_station_id#5010,end_station_name#5011,end_station_id#5012,start_lat#5013,start_lng#5014,end_lat#5015,end_lng#5016,member_casual#5017,month#5018] PushedFilters: [], ReadSchema: struct<ride_id:string,rideable_type:string,started_at:timestamp,ended_at:timestamp,start_station_...\n",
      " MapPartitionsRDD[164] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/01/02 20:01:22 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0\n",
      "25/01/02 20:01:22 INFO DAGScheduler: Got job 37 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/01/02 20:01:22 INFO DAGScheduler: Final stage: ResultStage 49 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/01/02 20:01:22 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/01/02 20:01:22 INFO DAGScheduler: Missing parents: List()\n",
      "25/01/02 20:01:22 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 36) (macbookpro.fritz.box, executor driver, partition 0, PROCESS_LOCAL, 9033 bytes) \n",
      "25/01/02 20:01:22 INFO DAGScheduler: Submitting ResultStage 49 (*(1) Scan JDBCRelation(station_status_transformed) [numPartitions=1] [station_id#5117,name#5118,short_name#5119,region_id#5120,lat#5121,lon#5122,capacity#5123,has_kiosk#5124,installed#5125,is_installed#5126,is_returning#5127,is_renting#5128,avg_bikes_available#5129,avg_docks_available#5130,status_last_reported#5131,info_last_reported#5132,aggregation_date#5133] PushedFilters: [], ReadSchema: struct<station_id:string,name:string,short_name:string,region_id:string,lat:decimal(38,18),lon:de...\n",
      " MapPartitionsRDD[167] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/01/02 20:01:22 INFO Executor: Running task 0.0 in stage 48.0 (TID 36)\n",
      "25/01/02 20:01:22 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 20.8 KiB, free 6.0 GiB)\n",
      "25/01/02 20:01:22 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 6.0 GiB)\n",
      "25/01/02 20:01:22 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on macbookpro.fritz.box:53671 (size: 9.1 KiB, free: 6.2 GiB)\n",
      "25/01/02 20:01:22 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1585\n",
      "25/01/02 20:01:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (*(1) Scan JDBCRelation(station_status_transformed) [numPartitions=1] [station_id#5117,name#5118,short_name#5119,region_id#5120,lat#5121,lon#5122,capacity#5123,has_kiosk#5124,installed#5125,is_installed#5126,is_returning#5127,is_renting#5128,avg_bikes_available#5129,avg_docks_available#5130,status_last_reported#5131,info_last_reported#5132,aggregation_date#5133] PushedFilters: [], ReadSchema: struct<station_id:string,name:string,short_name:string,region_id:string,lat:decimal(38,18),lon:de...\n",
      " MapPartitionsRDD[167] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/01/02 20:01:22 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks resource profile 0\n",
      "25/01/02 20:01:22 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 37) (macbookpro.fritz.box, executor driver, partition 0, PROCESS_LOCAL, 9033 bytes) \n",
      "25/01/02 20:01:22 INFO Executor: Running task 0.0 in stage 49.0 (TID 37)\n",
      "25/01/02 20:01:22 INFO CodeGenerator: Code generated in 32.71 ms\n",
      "25/01/02 20:01:23 INFO JDBCRDD: closed connection\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/Users/tobi/Documents/projects/citibike-stream/citivenv/lib/python3.13/site-packages/pyspark/jars/spark-core_2.12-3.5.4.jar) to field java.math.BigDecimal.intVal\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "25/01/02 20:01:23 INFO MemoryStore: Block rdd_167_0 stored as values in memory (estimated size 321.9 KiB, free 6.0 GiB)\n",
      "25/01/02 20:01:23 INFO BlockManagerInfo: Added rdd_167_0 in memory on macbookpro.fritz.box:53671 (size: 321.9 KiB, free: 6.2 GiB)\n",
      "25/01/02 20:01:23 INFO Executor: 1 block locks were not released by task 0.0 in stage 49.0 (TID 37)\n",
      "[rdd_167_0]\n",
      "25/01/02 20:01:23 INFO Executor: Finished task 0.0 in stage 49.0 (TID 37). 1445 bytes result sent to driver\n",
      "25/01/02 20:01:23 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 37) in 453 ms on macbookpro.fritz.box (executor driver) (1/1)\n",
      "25/01/02 20:01:23 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool \n",
      "25/01/02 20:01:23 INFO DAGScheduler: ResultStage 49 (showString at NativeMethodAccessorImpl.java:0) finished in 0,473 s\n",
      "25/01/02 20:01:23 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/01/02 20:01:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 49: Stage finished\n",
      "25/01/02 20:01:23 INFO CodeGenerator: Code generated in 11.6375 ms\n",
      "25/01/02 20:01:23 INFO DefaultCachedBatchSerializer: Predicate isnotnull(short_name#5119) generates partition filter: ((short_name.count#6061 - short_name.nullCount#6060) > 0)\n",
      "25/01/02 20:01:23 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "25/01/02 20:01:23 INFO DAGScheduler: Got job 38 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions\n",
      "25/01/02 20:01:23 INFO DAGScheduler: Final stage: ResultStage 50 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)\n",
      "25/01/02 20:01:23 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/01/02 20:01:23 INFO DAGScheduler: Missing parents: List()\n",
      "25/01/02 20:01:23 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[172] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents\n",
      "25/01/02 20:01:23 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 36.6 KiB, free 6.0 GiB)\n",
      "25/01/02 20:01:23 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 15.4 KiB, free 6.0 GiB)\n",
      "25/01/02 20:01:23 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on macbookpro.fritz.box:53671 (size: 15.4 KiB, free: 6.2 GiB)\n",
      "25/01/02 20:01:23 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1585\n",
      "25/01/02 20:01:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[172] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))\n",
      "25/01/02 20:01:23 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks resource profile 0\n",
      "25/01/02 20:01:23 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 38) (macbookpro.fritz.box, executor driver, partition 0, PROCESS_LOCAL, 9033 bytes) \n",
      "25/01/02 20:01:23 INFO Executor: Running task 0.0 in stage 50.0 (TID 38)\n",
      "25/01/02 20:01:23 INFO BlockManager: Found block rdd_167_0 locally\n",
      "25/01/02 20:01:23 INFO CodeGenerator: Code generated in 5.711417 ms (0 + 1) / 1]\n",
      "25/01/02 20:01:23 INFO CodeGenerator: Code generated in 25.204 ms\n",
      "25/01/02 20:01:23 INFO BlockManagerInfo: Removed broadcast_45_piece0 on macbookpro.fritz.box:53671 in memory (size: 33.8 KiB, free: 6.2 GiB)\n",
      "25/01/02 20:01:23 INFO CodeGenerator: Code generated in 16.366083 ms\n",
      "25/01/02 20:01:23 INFO Executor: Finished task 0.0 in stage 50.0 (TID 38). 233183 bytes result sent to driver\n",
      "25/01/02 20:01:23 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 38) in 175 ms on macbookpro.fritz.box (executor driver) (1/1)\n",
      "25/01/02 20:01:23 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool \n",
      "25/01/02 20:01:23 INFO DAGScheduler: ResultStage 50 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,183 s\n",
      "25/01/02 20:01:23 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/01/02 20:01:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 50: Stage finished\n",
      "25/01/02 20:01:23 INFO DAGScheduler: Job 38 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,192690 s\n",
      "25/01/02 20:01:23 INFO CodeGenerator: Code generated in 6.559042 ms             \n",
      "25/01/02 20:01:23 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 64.1 MiB, free 6.0 GiB)\n",
      "25/01/02 20:01:23 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 247.0 KiB, free 6.0 GiB)\n",
      "25/01/02 20:01:23 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on macbookpro.fritz.box:53671 (size: 247.0 KiB, free: 6.2 GiB)\n",
      "25/01/02 20:01:23 INFO SparkContext: Created broadcast 50 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "25/01/02 20:01:24 INFO BlockManagerInfo: Removed broadcast_49_piece0 on macbookpro.fritz.box:53671 in memory (size: 15.4 KiB, free: 6.2 GiB)\n",
      "25/01/02 20:01:24 INFO BlockManagerInfo: Removed broadcast_48_piece0 on macbookpro.fritz.box:53671 in memory (size: 9.1 KiB, free: 6.2 GiB)\n",
      "25/01/02 20:01:24 INFO BlockManagerInfo: Removed broadcast_44_piece0 on macbookpro.fritz.box:53671 in memory (size: 220.0 KiB, free: 6.2 GiB)\n",
      "25/01/02 20:01:29 INFO CodeGenerator: Code generated in 8.424875 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+-------------------+-------------------+--------------------+----------------+--------------------+--------------+---------+----------+---------+----------+-------------+----------+------------------------+--------------------+--------------------+--------------------+--------------+-------------------------+-------------------------+--------------------------+------------------------+\n",
      "|         ride_id|rideable_type|         started_at|           ended_at|  start_station_name|start_station_id|    end_station_name|end_station_id|start_lat| start_lng|  end_lat|   end_lng|member_casual|     month|start_station_short_name|  start_station_name|           start_lat|           start_lon|start_capacity|start_avg_bikes_available|start_avg_docks_available|start_status_last_reported|start_info_last_reported|\n",
      "+----------------+-------------+-------------------+-------------------+--------------------+----------------+--------------------+--------------+---------+----------+---------+----------+-------------+----------+------------------------+--------------------+--------------------+--------------------+--------------+-------------------------+-------------------------+--------------------------+------------------------+\n",
      "|3F874FD7056276BA|electric_bike|2024-10-31 00:00:00|2024-11-01 00:00:00|    W 30 St & 10 Ave|         6459.07|Cleveland Pl & Sp...|       5492.05|40.752694|-74.002353|40.722104|-73.997249|       member|2024-10-01|                 6459.07|    W 30 St & 10 Ave|40.75269400000000...|-74.0023530000000...|            56|     34.05221674876850...|     19.83448275862070...|       2025-01-02 18:40:37|    2024-12-30 14:21:...|\n",
      "|E4FE320A5D6A8901| classic_bike|2024-10-31 00:00:00|2024-11-01 00:00:00|Sullivan St & Was...|         5721.01|Cleveland Pl & Sp...|       5492.05|40.730477|-73.999061|40.722104|-73.997249|       casual|2024-10-01|                 5721.01|Sullivan St & Was...|40.73047747000000...|-73.9990606500000...|            57|     40.16847290640390...|     15.01970443349750...|       2025-01-02 18:40:04|    2024-12-30 14:21:...|\n",
      "|D9B974903E41D0C6|electric_bike|2024-10-31 00:00:00|2024-11-01 00:00:00|Sullivan St & Was...|         5721.01|Cleveland Pl & Sp...|       5492.05|40.730477|-73.999061|40.722104|-73.997249|       casual|2024-10-01|                 5721.01|Sullivan St & Was...|40.73047747000000...|-73.9990606500000...|            57|     40.16847290640390...|     15.01970443349750...|       2025-01-02 18:40:04|    2024-12-30 14:21:...|\n",
      "|35AE372A27FAE5AC|electric_bike|2024-10-31 00:00:00|2024-11-01 00:00:00|     E 88 St & 1 Ave|         7235.13|     6 Ave & W 34 St|        6364.1|40.778301|-73.948813|40.749640|-73.988050|       member|2024-10-01|                 7235.13|     E 88 St & 1 Ave|40.77830100000000...|-73.9488134000000...|            39|     21.80158730158730...|     15.08928571428570...|       2025-01-02 18:40:20|    2024-12-30 14:21:...|\n",
      "|35AE372A27FAE5AC|electric_bike|2024-10-31 00:00:00|2024-11-01 00:00:00|     E 88 St & 1 Ave|         7235.13|     6 Ave & W 34 St|        6364.1|40.778301|-73.948813|40.749640|-73.988050|       member|2024-10-01|                 7235.13|     E 88 St & 1 Ave|40.77830100000000...|-73.9488134000000...|            39|     2.285714285714290000|     19.00000000000000...|       2024-12-30 16:05:16|    2024-12-30 14:21:...|\n",
      "+----------------+-------------+-------------------+-------------------+--------------------+----------------+--------------------+--------------+---------+----------+---------+----------+-------------+----------+------------------------+--------------------+--------------------+--------------------+--------------+-------------------------+-------------------------+--------------------------+------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 20:01:42 INFO JDBCRDD: closed connection\n",
      "25/01/02 20:01:42 INFO MemoryStore: Block rdd_164_0 stored as values in memory (estimated size 124.3 MiB, free 5.9 GiB)\n",
      "25/01/02 20:01:42 INFO BlockManagerInfo: Added rdd_164_0 in memory on macbookpro.fritz.box:53671 (size: 124.3 MiB, free: 6.0 GiB)\n",
      "25/01/02 20:01:42 INFO Executor: 1 block locks were not released by task 0.0 in stage 48.0 (TID 36)\n",
      "[rdd_164_0]\n",
      "25/01/02 20:01:42 INFO Executor: Finished task 0.0 in stage 48.0 (TID 36). 1402 bytes result sent to driver\n",
      "25/01/02 20:01:42 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 36) in 19982 ms on macbookpro.fritz.box (executor driver) (1/1)\n",
      "25/01/02 20:01:42 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool \n",
      "25/01/02 20:01:42 INFO DAGScheduler: ResultStage 48 (showString at NativeMethodAccessorImpl.java:0) finished in 20,005 s\n",
      "25/01/02 20:01:42 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/01/02 20:01:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished\n",
      "25/01/02 20:01:42 INFO CodeGenerator: Code generated in 27.026958 ms\n",
      "25/01/02 20:01:42 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "25/01/02 20:01:42 INFO DAGScheduler: Got job 39 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/01/02 20:01:42 INFO DAGScheduler: Final stage: ResultStage 51 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/01/02 20:01:42 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/01/02 20:01:42 INFO DAGScheduler: Missing parents: List()\n",
      "25/01/02 20:01:42 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[177] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/01/02 20:01:42 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 37.7 KiB, free 5.9 GiB)\n",
      "25/01/02 20:01:42 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 5.9 GiB)\n",
      "25/01/02 20:01:42 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on macbookpro.fritz.box:53671 (size: 14.7 KiB, free: 6.0 GiB)\n",
      "25/01/02 20:01:42 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1585\n",
      "25/01/02 20:01:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[177] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/01/02 20:01:42 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks resource profile 0\n",
      "25/01/02 20:01:42 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 39) (macbookpro.fritz.box, executor driver, partition 0, PROCESS_LOCAL, 9033 bytes) \n",
      "25/01/02 20:01:42 INFO Executor: Running task 0.0 in stage 51.0 (TID 39)\n",
      "25/01/02 20:01:42 INFO BlockManager: Found block rdd_164_0 locally\n",
      "25/01/02 20:01:42 INFO CodeGenerator: Code generated in 2.401958 ms\n",
      "25/01/02 20:01:42 INFO CodeGenerator: Code generated in 7.502542 ms\n",
      "25/01/02 20:01:42 INFO CodeGenerator: Code generated in 9.461584 ms\n",
      "25/01/02 20:01:42 INFO BlockManagerInfo: Removed broadcast_47_piece0 on macbookpro.fritz.box:53671 in memory (size: 8.7 KiB, free: 6.0 GiB)\n",
      "25/01/02 20:01:42 INFO Executor: 1 block locks were not released by task 0.0 in stage 51.0 (TID 39)\n",
      "[rdd_164_0]\n",
      "25/01/02 20:01:42 INFO Executor: Finished task 0.0 in stage 51.0 (TID 39). 3346 bytes result sent to driver\n",
      "25/01/02 20:01:42 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 39) in 94 ms on macbookpro.fritz.box (executor driver) (1/1)\n",
      "25/01/02 20:01:42 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool \n",
      "25/01/02 20:01:42 INFO DAGScheduler: ResultStage 51 (showString at NativeMethodAccessorImpl.java:0) finished in 0,105 s\n",
      "25/01/02 20:01:42 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/01/02 20:01:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished\n",
      "25/01/02 20:01:42 INFO DAGScheduler: Job 39 finished: showString at NativeMethodAccessorImpl.java:0, took 0,108262 s\n",
      "25/01/02 20:01:42 INFO CodeGenerator: Code generated in 11.405042 ms            \n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T19:15:56.894264Z",
     "start_time": "2025-01-02T19:15:56.436172Z"
    }
   },
   "cell_type": "code",
   "source": "final_df.show(5)",
   "id": "a94d86dd25ff759a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 20:15:56 INFO DefaultCachedBatchSerializer: Predicate isnotnull(short_name#5119) generates partition filter: ((short_name.count#8802 - short_name.nullCount#8801) > 0)\n",
      "25/01/02 20:15:56 INFO DefaultCachedBatchSerializer: Predicate isnotnull(short_name#7691) generates partition filter: ((short_name.count#8887 - short_name.nullCount#8886) > 0)\n",
      "25/01/02 20:15:56 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "25/01/02 20:15:56 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "25/01/02 20:15:56 INFO DAGScheduler: Got job 43 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions\n",
      "25/01/02 20:15:56 INFO DAGScheduler: Final stage: ResultStage 55 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)\n",
      "25/01/02 20:15:56 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/01/02 20:15:56 INFO DAGScheduler: Missing parents: List()\n",
      "25/01/02 20:15:56 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[202] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents\n",
      "25/01/02 20:15:56 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 38.6 KiB, free 6.0 GiB)\n",
      "25/01/02 20:15:56 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 16.1 KiB, free 6.0 GiB)\n",
      "25/01/02 20:15:56 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on macbookpro.fritz.box:53671 (size: 16.1 KiB, free: 6.0 GiB)\n",
      "25/01/02 20:15:56 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1585\n",
      "25/01/02 20:15:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[202] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))\n",
      "25/01/02 20:15:56 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks resource profile 0\n",
      "25/01/02 20:15:56 INFO DAGScheduler: Got job 44 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions\n",
      "25/01/02 20:15:56 INFO DAGScheduler: Final stage: ResultStage 56 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)\n",
      "25/01/02 20:15:56 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/01/02 20:15:56 INFO DAGScheduler: Missing parents: List()\n",
      "25/01/02 20:15:56 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[201] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents\n",
      "25/01/02 20:15:56 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 43) (macbookpro.fritz.box, executor driver, partition 0, PROCESS_LOCAL, 9033 bytes) \n",
      "25/01/02 20:15:56 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 36.6 KiB, free 6.0 GiB)\n",
      "25/01/02 20:15:56 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 15.4 KiB, free 6.0 GiB)\n",
      "25/01/02 20:15:56 INFO Executor: Running task 0.0 in stage 55.0 (TID 43)\n",
      "25/01/02 20:15:56 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on macbookpro.fritz.box:53671 (size: 15.4 KiB, free: 6.0 GiB)\n",
      "25/01/02 20:15:56 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1585\n",
      "25/01/02 20:15:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[201] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))\n",
      "25/01/02 20:15:56 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks resource profile 0\n",
      "25/01/02 20:15:56 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 44) (macbookpro.fritz.box, executor driver, partition 0, PROCESS_LOCAL, 9033 bytes) \n",
      "25/01/02 20:15:56 INFO Executor: Running task 0.0 in stage 56.0 (TID 44)\n",
      "25/01/02 20:15:56 INFO BlockManager: Found block rdd_167_0 locally\n",
      "25/01/02 20:15:56 INFO BlockManager: Found block rdd_167_0 locally\n",
      "25/01/02 20:15:56 INFO Executor: Finished task 0.0 in stage 56.0 (TID 44). 233183 bytes result sent to driver\n",
      "25/01/02 20:15:56 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 44) in 15 ms on macbookpro.fritz.box (executor driver) (1/1)\n",
      "25/01/02 20:15:56 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool \n",
      "25/01/02 20:15:56 INFO DAGScheduler: ResultStage 56 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,026 s\n",
      "25/01/02 20:15:56 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/01/02 20:15:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 56: Stage finished\n",
      "25/01/02 20:15:56 INFO DAGScheduler: Job 44 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,055489 s\n",
      "25/01/02 20:15:56 INFO Executor: Finished task 0.0 in stage 55.0 (TID 43). 233226 bytes result sent to driver\n",
      "25/01/02 20:15:56 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 43) in 35 ms on macbookpro.fritz.box (executor driver) (1/1)\n",
      "25/01/02 20:15:56 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool \n",
      "25/01/02 20:15:56 INFO DAGScheduler: ResultStage 55 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,059 s\n",
      "25/01/02 20:15:56 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/01/02 20:15:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished\n",
      "25/01/02 20:15:56 INFO DAGScheduler: Job 43 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,062505 s\n",
      "25/01/02 20:15:56 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 64.1 MiB, free 5.9 GiB)\n",
      "25/01/02 20:15:56 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 64.1 MiB, free 5.9 GiB)\n",
      "25/01/02 20:15:56 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 247.0 KiB, free 5.9 GiB)\n",
      "25/01/02 20:15:56 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 247.0 KiB, free 5.9 GiB)\n",
      "25/01/02 20:15:56 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on macbookpro.fritz.box:53671 (size: 247.0 KiB, free: 6.0 GiB)\n",
      "25/01/02 20:15:56 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on macbookpro.fritz.box:53671 (size: 247.0 KiB, free: 6.0 GiB)\n",
      "25/01/02 20:15:56 INFO SparkContext: Created broadcast 60 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "25/01/02 20:15:56 INFO SparkContext: Created broadcast 59 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+-------------------+-------------------+--------------------+----------------+--------------------+--------------+---------+----------+---------+----------+-------------+----------+------------------------+--------------------+--------------------+--------------------+--------------+-------------------------+-------------------------+--------------------------+------------------------+----------------------+--------------------+--------------------+--------------------+------------+-----------------------+-----------------------+------------------------+----------------------+\n",
      "|         ride_id|rideable_type|         started_at|           ended_at|  start_station_name|start_station_id|    end_station_name|end_station_id|start_lat| start_lng|  end_lat|   end_lng|member_casual|     month|start_station_short_name|  start_station_name|           start_lat|           start_lon|start_capacity|start_avg_bikes_available|start_avg_docks_available|start_status_last_reported|start_info_last_reported|end_station_short_name|    end_station_name|             end_lat|             end_lon|end_capacity|end_avg_bikes_available|end_avg_docks_available|end_status_last_reported|end_info_last_reported|\n",
      "+----------------+-------------+-------------------+-------------------+--------------------+----------------+--------------------+--------------+---------+----------+---------+----------+-------------+----------+------------------------+--------------------+--------------------+--------------------+--------------+-------------------------+-------------------------+--------------------------+------------------------+----------------------+--------------------+--------------------+--------------------+------------+-----------------------+-----------------------+------------------------+----------------------+\n",
      "|3F874FD7056276BA|electric_bike|2024-10-31 00:00:00|2024-11-01 00:00:00|    W 30 St & 10 Ave|         6459.07|Cleveland Pl & Sp...|       5492.05|40.752694|-74.002353|40.722104|-73.997249|       member|2024-10-01|                 6459.07|    W 30 St & 10 Ave|40.75269400000000...|-74.0023530000000...|            56|     34.05221674876850...|     19.83448275862070...|       2025-01-02 18:40:37|    2024-12-30 14:21:...|               5492.05|Cleveland Pl & Sp...|40.72210378668600...|-73.9972490072250...|          33|   23.04532019704430...|   8.724137931034480000|     2025-01-02 18:40:21|  2024-12-30 14:21:...|\n",
      "|E4FE320A5D6A8901| classic_bike|2024-10-31 00:00:00|2024-11-01 00:00:00|Sullivan St & Was...|         5721.01|Cleveland Pl & Sp...|       5492.05|40.730477|-73.999061|40.722104|-73.997249|       casual|2024-10-01|                 5721.01|Sullivan St & Was...|40.73047747000000...|-73.9990606500000...|            57|     40.16847290640390...|     15.01970443349750...|       2025-01-02 18:40:04|    2024-12-30 14:21:...|               5492.05|Cleveland Pl & Sp...|40.72210378668600...|-73.9972490072250...|          33|   23.04532019704430...|   8.724137931034480000|     2025-01-02 18:40:21|  2024-12-30 14:21:...|\n",
      "|D9B974903E41D0C6|electric_bike|2024-10-31 00:00:00|2024-11-01 00:00:00|Sullivan St & Was...|         5721.01|Cleveland Pl & Sp...|       5492.05|40.730477|-73.999061|40.722104|-73.997249|       casual|2024-10-01|                 5721.01|Sullivan St & Was...|40.73047747000000...|-73.9990606500000...|            57|     40.16847290640390...|     15.01970443349750...|       2025-01-02 18:40:04|    2024-12-30 14:21:...|               5492.05|Cleveland Pl & Sp...|40.72210378668600...|-73.9972490072250...|          33|   23.04532019704430...|   8.724137931034480000|     2025-01-02 18:40:21|  2024-12-30 14:21:...|\n",
      "|35AE372A27FAE5AC|electric_bike|2024-10-31 00:00:00|2024-11-01 00:00:00|     E 88 St & 1 Ave|         7235.13|     6 Ave & W 34 St|        6364.1|40.778301|-73.948813|40.749640|-73.988050|       member|2024-10-01|                 7235.13|     E 88 St & 1 Ave|40.77830100000000...|-73.9488134000000...|            39|     21.80158730158730...|     15.08928571428570...|       2025-01-02 18:40:20|    2024-12-30 14:21:...|                  NULL|                NULL|                NULL|                NULL|        NULL|                   NULL|                   NULL|                    NULL|                  NULL|\n",
      "|35AE372A27FAE5AC|electric_bike|2024-10-31 00:00:00|2024-11-01 00:00:00|     E 88 St & 1 Ave|         7235.13|     6 Ave & W 34 St|        6364.1|40.778301|-73.948813|40.749640|-73.988050|       member|2024-10-01|                 7235.13|     E 88 St & 1 Ave|40.77830100000000...|-73.9488134000000...|            39|     2.285714285714290000|     19.00000000000000...|       2024-12-30 16:05:16|    2024-12-30 14:21:...|                  NULL|                NULL|                NULL|                NULL|        NULL|                   NULL|                   NULL|                    NULL|                  NULL|\n",
      "+----------------+-------------+-------------------+-------------------+--------------------+----------------+--------------------+--------------+---------+----------+---------+----------+-------------+----------+------------------------+--------------------+--------------------+--------------------+--------------+-------------------------+-------------------------+--------------------------+------------------------+----------------------+--------------------+--------------------+--------------------+------------+-----------------------+-----------------------+------------------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 20:15:56 INFO CodeGenerator: Code generated in 22.124709 ms\n",
      "25/01/02 20:15:56 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "25/01/02 20:15:56 INFO DAGScheduler: Got job 45 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/01/02 20:15:56 INFO DAGScheduler: Final stage: ResultStage 57 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/01/02 20:15:56 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/01/02 20:15:56 INFO DAGScheduler: Missing parents: List()\n",
      "25/01/02 20:15:56 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[207] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/01/02 20:15:56 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 44.6 KiB, free 5.9 GiB)\n",
      "25/01/02 20:15:56 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 5.9 GiB)\n",
      "25/01/02 20:15:56 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on macbookpro.fritz.box:53671 (size: 16.3 KiB, free: 6.0 GiB)\n",
      "25/01/02 20:15:56 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1585\n",
      "25/01/02 20:15:56 INFO BlockManagerInfo: Removed broadcast_58_piece0 on macbookpro.fritz.box:53671 in memory (size: 15.4 KiB, free: 6.0 GiB)\n",
      "25/01/02 20:15:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[207] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/01/02 20:15:56 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0\n",
      "25/01/02 20:15:56 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 45) (macbookpro.fritz.box, executor driver, partition 0, PROCESS_LOCAL, 9033 bytes) \n",
      "25/01/02 20:15:56 INFO Executor: Running task 0.0 in stage 57.0 (TID 45)\n",
      "25/01/02 20:15:56 INFO BlockManagerInfo: Removed broadcast_57_piece0 on macbookpro.fritz.box:53671 in memory (size: 16.1 KiB, free: 6.0 GiB)\n",
      "25/01/02 20:15:56 INFO BlockManager: Found block rdd_164_0 locally\n",
      "25/01/02 20:15:56 INFO CodeGenerator: Code generated in 26.130541 ms\n",
      "25/01/02 20:15:56 INFO Executor: 1 block locks were not released by task 0.0 in stage 57.0 (TID 45)\n",
      "[rdd_164_0]\n",
      "25/01/02 20:15:56 INFO Executor: Finished task 0.0 in stage 57.0 (TID 45). 3694 bytes result sent to driver\n",
      "25/01/02 20:15:56 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 45) in 44 ms on macbookpro.fritz.box (executor driver) (1/1)\n",
      "25/01/02 20:15:56 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool \n",
      "25/01/02 20:15:56 INFO DAGScheduler: ResultStage 57 (showString at NativeMethodAccessorImpl.java:0) finished in 0,060 s\n",
      "25/01/02 20:15:56 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/01/02 20:15:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished\n",
      "25/01/02 20:15:56 INFO DAGScheduler: Job 45 finished: showString at NativeMethodAccessorImpl.java:0, took 0,065050 s\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T19:28:53.668386Z",
     "start_time": "2025-01-02T19:28:53.664404Z"
    }
   },
   "cell_type": "code",
   "source": "final_df.printSchema()",
   "id": "b686b9b233609e32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ride_id: string (nullable = true)\n",
      " |-- rideable_type: string (nullable = true)\n",
      " |-- started_at: timestamp (nullable = true)\n",
      " |-- ended_at: timestamp (nullable = true)\n",
      " |-- original_start_station_name: string (nullable = true)\n",
      " |-- start_station_id: string (nullable = true)\n",
      " |-- original_end_station_name: string (nullable = true)\n",
      " |-- end_station_id: string (nullable = true)\n",
      " |-- original_start_lat: decimal(9,6) (nullable = true)\n",
      " |-- start_lng: decimal(9,6) (nullable = true)\n",
      " |-- original_end_lat: decimal(9,6) (nullable = true)\n",
      " |-- end_lng: decimal(9,6) (nullable = true)\n",
      " |-- member_casual: string (nullable = true)\n",
      " |-- month: date (nullable = true)\n",
      " |-- start_station_short_name: string (nullable = true)\n",
      " |-- start_station_name: string (nullable = true)\n",
      " |-- start_lat: decimal(38,18) (nullable = true)\n",
      " |-- start_lon: decimal(38,18) (nullable = true)\n",
      " |-- start_capacity: integer (nullable = true)\n",
      " |-- start_avg_bikes_available: decimal(38,18) (nullable = true)\n",
      " |-- start_avg_docks_available: decimal(38,18) (nullable = true)\n",
      " |-- start_status_last_reported: timestamp (nullable = true)\n",
      " |-- start_info_last_reported: timestamp (nullable = true)\n",
      " |-- end_station_short_name: string (nullable = true)\n",
      " |-- end_station_name: string (nullable = true)\n",
      " |-- end_lat: decimal(38,18) (nullable = true)\n",
      " |-- end_lon: decimal(38,18) (nullable = true)\n",
      " |-- end_capacity: integer (nullable = true)\n",
      " |-- end_avg_bikes_available: decimal(38,18) (nullable = true)\n",
      " |-- end_avg_docks_available: decimal(38,18) (nullable = true)\n",
      " |-- end_status_last_reported: timestamp (nullable = true)\n",
      " |-- end_info_last_reported: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T19:03:12.226340Z",
     "start_time": "2025-01-02T19:03:12.027119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "CREATE TABLE agg_tripdata (\n",
    "    ride_id VARCHAR PRIMARY KEY,\n",
    "    rideable_type VARCHAR,\n",
    "    started_at TIMESTAMP,\n",
    "    ended_at TIMESTAMP,\n",
    "    member_casual VARCHAR,\n",
    "    month DATE,\n",
    "    start_station_id VARCHAR,\n",
    "    start_station_name_enriched VARCHAR,\n",
    "    start_lat_enriched DECIMAL(38,18),\n",
    "    start_lng DECIMAL(9,6),\n",
    "    start_lon_enriched DECIMAL(38,18),\n",
    "    start_capacity INTEGER,\n",
    "    start_avg_bikes_available DECIMAL(38,18),\n",
    "    start_avg_docks_available DECIMAL(38,18),\n",
    "    start_status_last_reported TIMESTAMP,\n",
    "    start_info_last_reported TIMESTAMP,\n",
    "    end_station_id VARCHAR,\n",
    "    end_station_name_enriched VARCHAR,\n",
    "    end_lat_enriched DECIMAL(38,18),\n",
    "    end_lng DECIMAL(9,6),\n",
    "    end_lon_enriched DECIMAL(38,18),\n",
    "    end_capacity INTEGER,\n",
    "    end_avg_bikes_available DECIMAL(38,18),\n",
    "    end_avg_docks_available DECIMAL(38,18),\n",
    "    end_status_last_reported TIMESTAMP,\n",
    "    end_info_last_reported TIMESTAMP,\n",
    "    trip_duration_seconds BIGINT,\n",
    "    aggregation_date DATE\n",
    ");\n",
    "\"\"\""
   ],
   "id": "8547ff231ecebd8d",
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[AMBIGUOUS_REFERENCE] Reference `start_station_name` is ambiguous, could be: [`start_station_name`, `start_station_name`].",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[53], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m final_df \u001B[38;5;241m=\u001B[39m \u001B[43mfinal_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mride_id\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrideable_type\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstarted_at\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mended_at\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmember_casual\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmonth\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstart_station_id\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstart_station_name\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstart_lat\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstart_lng\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstart_capacity\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstart_avg_bikes_available\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstart_avg_docks_available\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstart_status_last_reported\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstart_info_last_reported\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mend_station_id\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mend_station_name\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mend_lat\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mend_lng\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mend_capacity\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mend_avg_bikes_available\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mend_avg_docks_available\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     24\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mend_status_last_reported\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mend_info_last_reported\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[1;32m     26\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/projects/citibike-stream/citivenv/lib/python3.13/site-packages/pyspark/sql/dataframe.py:3229\u001B[0m, in \u001B[0;36mDataFrame.select\u001B[0;34m(self, *cols)\u001B[0m\n\u001B[1;32m   3184\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mselect\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39mcols: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mColumnOrName\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m:  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   3185\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001B[39;00m\n\u001B[1;32m   3186\u001B[0m \n\u001B[1;32m   3187\u001B[0m \u001B[38;5;124;03m    .. versionadded:: 1.3.0\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3227\u001B[0m \u001B[38;5;124;03m    +-----+---+\u001B[39;00m\n\u001B[1;32m   3228\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 3229\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jcols\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcols\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3230\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
      "File \u001B[0;32m~/Documents/projects/citibike-stream/citivenv/lib/python3.13/site-packages/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m~/Documents/projects/citibike-stream/citivenv/lib/python3.13/site-packages/pyspark/errors/exceptions/captured.py:185\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    181\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    183\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    184\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 185\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    187\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[0;31mAnalysisException\u001B[0m: [AMBIGUOUS_REFERENCE] Reference `start_station_name` is ambiguous, could be: [`start_station_name`, `start_station_name`]."
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T19:30:54.703194Z",
     "start_time": "2025-01-02T19:30:54.516621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_df.write \\\n",
    "    .jdbc(url=jdbc_url,\n",
    "          table=\"agg_tripdata\",\n",
    "          mode=\"append\",\n",
    "          properties=connection_properties\n",
    "          )"
   ],
   "id": "bff75c5531a3fedf",
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Column start_station_id not found in schema Some(StructType(StructField(ride_id,StringType,true),StructField(rideable_type,StringType,true),StructField(started_at,TimestampType,true),StructField(ended_at,TimestampType,true),StructField(original_start_station_name,StringType,true),StructField(original_start_lat,DecimalType(38,18),true),StructField(original_end_station_name,StringType,true),StructField(original_end_lat,DecimalType(38,18),true),StructField(member_casual,StringType,true),StructField(month,IntegerType,true),StructField(start_station_short_name,StringType,true),StructField(start_station_name,StringType,true),StructField(start_lat,DecimalType(38,18),true),StructField(start_lon,DecimalType(38,18),true),StructField(start_capacity,IntegerType,true),StructField(start_avg_bikes_available,DecimalType(38,18),true),StructField(start_avg_docks_available,DecimalType(38,18),true),StructField(start_status_last_reported,TimestampType,true),StructField(start_info_last_reported,TimestampType,true),StructField(end_station_short_name,StringType,true),StructField(end_station_name,StringType,true),StructField(end_lat,DecimalType(38,18),true),StructField(end_lon,DecimalType(38,18),true),StructField(end_capacity,IntegerType,true),StructField(end_avg_bikes_available,DecimalType(38,18),true),StructField(end_avg_docks_available,DecimalType(38,18),true),StructField(end_status_last_reported,TimestampType,true),StructField(end_info_last_reported,TimestampType,true))).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[76], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[43mfinal_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[43m \u001B[49m\u001B[43m\\\u001B[49m\n\u001B[0;32m----> 2\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjdbc\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjdbc_url\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m          \u001B[49m\u001B[43mtable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43magg_tripdata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m          \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mappend\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m          \u001B[49m\u001B[43mproperties\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconnection_properties\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m          \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/projects/citibike-stream/citivenv/lib/python3.13/site-packages/pyspark/sql/readwriter.py:1984\u001B[0m, in \u001B[0;36mDataFrameWriter.jdbc\u001B[0;34m(self, url, table, mode, properties)\u001B[0m\n\u001B[1;32m   1982\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m properties:\n\u001B[1;32m   1983\u001B[0m     jprop\u001B[38;5;241m.\u001B[39msetProperty(k, properties[k])\n\u001B[0;32m-> 1984\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jwrite\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjdbc\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjprop\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/projects/citibike-stream/citivenv/lib/python3.13/site-packages/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m~/Documents/projects/citibike-stream/citivenv/lib/python3.13/site-packages/pyspark/errors/exceptions/captured.py:185\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    181\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    183\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    184\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 185\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    187\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[0;31mAnalysisException\u001B[0m: Column start_station_id not found in schema Some(StructType(StructField(ride_id,StringType,true),StructField(rideable_type,StringType,true),StructField(started_at,TimestampType,true),StructField(ended_at,TimestampType,true),StructField(original_start_station_name,StringType,true),StructField(original_start_lat,DecimalType(38,18),true),StructField(original_end_station_name,StringType,true),StructField(original_end_lat,DecimalType(38,18),true),StructField(member_casual,StringType,true),StructField(month,IntegerType,true),StructField(start_station_short_name,StringType,true),StructField(start_station_name,StringType,true),StructField(start_lat,DecimalType(38,18),true),StructField(start_lon,DecimalType(38,18),true),StructField(start_capacity,IntegerType,true),StructField(start_avg_bikes_available,DecimalType(38,18),true),StructField(start_avg_docks_available,DecimalType(38,18),true),StructField(start_status_last_reported,TimestampType,true),StructField(start_info_last_reported,TimestampType,true),StructField(end_station_short_name,StringType,true),StructField(end_station_name,StringType,true),StructField(end_lat,DecimalType(38,18),true),StructField(end_lon,DecimalType(38,18),true),StructField(end_capacity,IntegerType,true),StructField(end_avg_bikes_available,DecimalType(38,18),true),StructField(end_avg_docks_available,DecimalType(38,18),true),StructField(end_status_last_reported,TimestampType,true),StructField(end_info_last_reported,TimestampType,true)))."
     ]
    }
   ],
   "execution_count": 76
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
